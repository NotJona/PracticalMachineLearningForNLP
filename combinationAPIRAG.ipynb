{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": "!pip install python-dotenv pandas llama-index langchain langchain-community llama-index-embeddings-langchain  sentence-transformers llama-index-llms-openai deepseek",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T16:50:10.145998Z",
     "start_time": "2025-08-29T16:49:55.006883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "from llama_index.core import KeywordTableIndex, Settings, PromptTemplate\n",
    "from openai import OpenAI as OpenAIClient \n",
    "from llama_index.llms.openai import OpenAI as LlamaOpenAI\n",
    "import os\n",
    "from llama_index.core import VectorStoreIndex, StorageContext, load_index_from_storage\n",
    "from llama_index.core.schema import TextNode\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ],
   "id": "da95233f9da8a8e7",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T16:50:23.057573Z",
     "start_time": "2025-08-29T16:50:10.163609Z"
    }
   },
   "cell_type": "code",
   "source": "from functions import load_jsonl, combine_data, extract_dict_from_response, compute_f1, check_df, find_best_model",
   "id": "b869a575fdb93c60",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Global Variables ",
   "id": "5953551db886483d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T16:50:23.331554Z",
     "start_time": "2025-08-29T16:50:23.322641Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#data\n",
    "train_file_path = Path('data_germeval/train.jsonl')\n",
    "dev_file_path = Path('data_germeval/development.jsonl')\n",
    "\n",
    "#models\n",
    "bert_model = \"dbmdz/bert-base-german-uncased\"\n",
    "multilingual_e5_model = \"intfloat/multilingual-e5-large\"\n",
    "\n",
    "#save/load paths\n",
    "vector_index_bert_path = Path(\"vector_index_BERT\")\n",
    "vector_index_multilingual_e5_path = Path(\"vector_index_multilingual-e5\")\n",
    "keyword_index_save_path = Path(\"keyword_index\")\n",
    "\n",
    "#API keys\n",
    "load_dotenv()\n",
    "DEEPSEEK_API_KEY = os.getenv(\"DEEPSEEK_API_KEY_25\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY_25\")\n",
    "\n",
    "#which openAI model to use\n",
    "llm_model_openAI = \"gpt-3.5-turbo\"\n",
    "llm_model_deepseek = \"deepseek-chat\"\n",
    "deepseek_url = \"https://api.deepseek.com/v1\"\n",
    "\n",
    "#do we want to compute the vector index?\n",
    "run_this = True"
   ],
   "id": "b1882abaed0df79e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# The usual setup",
   "id": "f4836649ebda4d80"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T16:50:32.154496Z",
     "start_time": "2025-08-29T16:50:32.049905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = load_jsonl(train_file_path)\n",
    "train_data_labeled = combine_data(train_data)\n",
    "train_df = combine_data(train_data, dataframe = True)\n",
    "\n",
    "dev_data = load_jsonl(dev_file_path)\n",
    "dev_data_labeled = combine_data(dev_data)\n",
    "dev_df = combine_data(dev_data, dataframe = True)\n",
    "\n",
    "test_data = [dev_data_labeled[i]['text'] for i in range(100)]"
   ],
   "id": "32d5a1859014ec72",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# MAIN PART",
   "id": "c4debb84ea8feb2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Index Setup",
   "id": "7f90a5c911627392"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T16:50:23.388220Z",
     "start_time": "2025-08-29T16:50:23.382276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_training_nodes(df):\n",
    "    \"\"\"\n",
    "    Prepares our data for indexing.\n",
    "    :param df: dataframe \n",
    "    :return: TextNode object of our dataframe\n",
    "    \"\"\"\n",
    "    training_nodes = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        text_content = f\"\"\"\n",
    "        Example Text: {row['text']}\n",
    "        \"\"\"\n",
    "        \n",
    "        node = TextNode(\n",
    "        text=text_content,\n",
    "        metadata={\n",
    "        'original_text': row['text'],\n",
    "        'bin_maj_label': row['bin_maj_label'],\n",
    "        'bin_one_label': row['bin_one_label'],\n",
    "        'bin_all_label': row['bin_all_label'],\n",
    "        'multi_maj_label': row['multi_maj_label'],\n",
    "        'disagree_bin_label': row['disagree_bin_label'],\n",
    "        'index': index\n",
    "        }\n",
    "        )\n",
    "        training_nodes.append(node)\n",
    "    \n",
    "    return training_nodes"
   ],
   "id": "b4568e7ec85890e4",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T16:50:23.460449Z",
     "start_time": "2025-08-29T16:50:23.454702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_vector_index(load_path, embed_model):\n",
    "    \"\"\"\n",
    "    Loads precomputed index\n",
    "    :param load_path: str, path to precomputed index\n",
    "    :param embed_model: model to use for embeddings\n",
    "    :return: loaded index \n",
    "    \"\"\"\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=load_path)\n",
    "    index = load_index_from_storage(\n",
    "        storage_context, \n",
    "        embed_model=embed_model\n",
    "    )\n",
    "    print(f\"Index loaded from {load_path}!\")\n",
    "    return index"
   ],
   "id": "cdd76529d707270e",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T16:50:23.501903Z",
     "start_time": "2025-08-29T16:50:23.496601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_reload_vector_index(nodes, model_name):\n",
    "    \"\"\"\n",
    "    Creates or reloads a vector index using our nodes and LlamaIndex\n",
    "    :param nodes: list of nodes \n",
    "    :param model_name: str, indicates model to use for embeddings\n",
    "    :return: generated or reloaded index\n",
    "    \"\"\"\n",
    "    if model_name == \"Bert\":\n",
    "        embed_model = HuggingFaceEmbeddings(model_name=bert_model)\n",
    "        save_path = vector_index_bert_path\n",
    "    else:\n",
    "        embed_model = HuggingFaceEmbeddings(model_name=multilingual_e5_model)\n",
    "        save_path = vector_index_multilingual_e5_path\n",
    "    \n",
    "    if os.path.exists(save_path):\n",
    "        print(\"Loading existing index...\")\n",
    "        return load_vector_index(save_path, embed_model)\n",
    "    else:\n",
    "        print(\"Creating index...\")\n",
    "        index = VectorStoreIndex(\n",
    "            nodes,\n",
    "            embed_model=embed_model\n",
    "        )\n",
    "        \n",
    "        index.storage_context.persist(persist_dir=save_path)\n",
    "        print(f\"Index saved to {save_path}!\")\n",
    "        \n",
    "        return index"
   ],
   "id": "c794fa2a1c8eea62",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T16:50:23.551559Z",
     "start_time": "2025-08-29T16:50:23.547181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_keyword_index(load_path):\n",
    "    \"\"\"\n",
    "    Loads precomputed index\n",
    "    :param load_path: str, path to precomputed index\n",
    "    :return: loaded index \n",
    "    \"\"\"\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=load_path)\n",
    "    index = load_index_from_storage(\n",
    "        storage_context, \n",
    "    )\n",
    "    print(f\"Index loaded from {load_path}!\")\n",
    "    return index"
   ],
   "id": "411d12bc1a3b692",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T16:50:23.602850Z",
     "start_time": "2025-08-29T16:50:23.597595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_reload_keyword_index(nodes):\n",
    "    \"\"\"\n",
    "    Creates or reloads a vector index using our nodes and LlamaIndex\n",
    "    :param nodes: list of nodes \n",
    "    :return: generated or reloaded index\n",
    "    \"\"\"\n",
    "    llm = LlamaOpenAI(api_key=OPENAI_API_KEY, model=llm_model_openAI)\n",
    "    \n",
    "    Settings.llm = llm\n",
    "    \n",
    "    if os.path.exists(keyword_index_save_path):\n",
    "        print(\"Loading existing keyword index...\")\n",
    "        storage_context = StorageContext.from_defaults(persist_dir=keyword_index_save_path)\n",
    "        return load_index_from_storage(storage_context)  \n",
    "    else:\n",
    "        print(\"Creating keyword index...\")\n",
    "        index = KeywordTableIndex(nodes)  \n",
    "        \n",
    "        index.storage_context.persist(persist_dir=keyword_index_save_path)\n",
    "        print(f\"Keyword index saved to {keyword_index_save_path}!\")\n",
    "        \n",
    "        return index"
   ],
   "id": "71b19306b9d101f3",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# API Prompt Template Part",
   "id": "b142e856fdc819a0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T16:50:23.631546Z",
     "start_time": "2025-08-29T16:50:23.627286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "custom_prompt = PromptTemplate(\"\"\"\n",
    "    **Task:** Predict sexism annotation labels for a new text based on the following label definitions.\n",
    "    \n",
    "    **Label Definitions:**\n",
    "    - 'bin_maj_label': A majority of annotators found the text to be sexist.\n",
    "    - 'bin_one_label': At least one annotator found the text to be sexist.\n",
    "    - 'bin_all_label': All annotators found the text to be sexist.\n",
    "    - 'multi_maj_label': The multi-class label (integer from 0 to 4) that the most annotators assigned.\n",
    "    - 'disagree_bin_label': The annotators disagreed on the binary (sexist/not sexist) classification.\n",
    "    \n",
    "    **Examples from the Dataset:**\n",
    "    '{context_str}'\n",
    "    \n",
    "    **Text to Analyze:**\n",
    "    '{query_str}'\n",
    "    \n",
    "    **Instructions:**\n",
    "    Analyze the text above and predict its labels. Return ONLY a valid Python dictionary in exactly the following format \n",
    "    (no spaces or newlines!). <value> must always be an integer::\n",
    "    {{'bin_maj_label': <value>, 'bin_one_label': <value>, 'bin_all_label': <value>, 'multi_maj_label': <value>, 'disagree_bin_label': <value>}}\n",
    "    \"\"\")"
   ],
   "id": "5153092593c26061",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T16:50:23.658578Z",
     "start_time": "2025-08-29T16:50:23.652061Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_custom_prompt(query_text, top_k_examples):\n",
    "    context_str = \"\\n\".join([f\"Example {i+1}: {node.text} --> bin_maj_label : {node.metadata['bin_maj_label']}, \"\n",
    "                             f\"bin_one_label: {node.metadata['bin_one_label']}, \"\n",
    "                             f\"bin_all_label: {node.metadata['bin_all_label']}, \"\n",
    "                             f\"multi_maj_label: {node.metadata['multi_maj_label']}, \"\n",
    "                             f\"disagree_bin_label: {node.metadata['disagree_bin_label']}.\"  for i, node in enumerate(top_k_examples)])\n",
    "    return custom_prompt.format(query_str=query_text, context_str=context_str)\n",
    "    "
   ],
   "id": "b4d6db15dfe841f",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T16:50:23.677812Z",
     "start_time": "2025-08-29T16:50:23.672249Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def retrieve_with_llm_open_ai(query_text, index, top_k=5):\n",
    "    \"\"\"\n",
    "    Use query engine with custom prompt to generate labels in the format we need\n",
    "    :param query_text: str, text to analyze\n",
    "    :param index: index object, index to retrieve similar examples from.\n",
    "    :param top_k: int, number of examples to compare\n",
    "    :return: str, response\n",
    "    \"\"\"\n",
    "    llm = LlamaOpenAI(api_key=OPENAI_API_KEY)\n",
    "    \n",
    "    retriever = index.as_retriever(similarity_top_k=top_k)\n",
    "    retrieved_nodes = retriever.retrieve(query_text)\n",
    "    \n",
    "    prompt = build_custom_prompt(query_text, retrieved_nodes)\n",
    "    response = llm.complete(prompt)\n",
    "    \n",
    "    return response.text"
   ],
   "id": "dfffc0ccbed88c45",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T16:50:23.693738Z",
     "start_time": "2025-08-29T16:50:23.689345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def retrieve_with_llm_deepseek(query_text, index, top_k=5):\n",
    "    \"\"\"\n",
    "    Use query engine with custom prompt to generate labels in the format we need\n",
    "    :param query_text: str, text to analyze\n",
    "    :param index: index object, index to retrieve similar examples from.\n",
    "    :param top_k: int, number of éxamples to compare\n",
    "    :return: str, response\n",
    "    \"\"\"\n",
    "    client = OpenAIClient(api_key=DEEPSEEK_API_KEY,base_url=deepseek_url)\n",
    "    retriever = index.as_retriever(similarity_top_k=top_k)\n",
    "    retrieved_nodes = retriever.retrieve(query_text)\n",
    "    \n",
    "    prompt = build_custom_prompt(query_text, retrieved_nodes)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=llm_model_deepseek,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        #temperature=0.1,  \n",
    "        max_tokens=150\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ],
   "id": "7c233aeae368750c",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T16:50:23.710657Z",
     "start_time": "2025-08-29T16:50:23.703870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def retrieve_with_llm(query_text, index, llm_name, top_k=5):\n",
    "    \"\"\"\n",
    "    Use query engine with custom prompt to generate labels in the format we need\n",
    "    :param query_text: str, text to analyze\n",
    "    :param index: index object, index to retrieve similar examples from.\n",
    "    :param llm_name: str, llm to use, either OpenAi or DeepSeek\n",
    "    :param top_k: int, number of examples to compare\n",
    "    :return: str, response\n",
    "    \"\"\"\n",
    "    if llm_name == 'OpenAI':\n",
    "        return retrieve_with_llm_open_ai(query_text, index, top_k)\n",
    "    elif llm_name == 'DeepSeek':\n",
    "        return retrieve_with_llm_deepseek(query_text, index, top_k)\n",
    "    else:\n",
    "        print('llm_name has to be either OpenAI or DeepSeek')\n"
   ],
   "id": "fe967ab10fe91fb",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T16:50:23.727788Z",
     "start_time": "2025-08-29T16:50:23.723050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_proper_response(query_text, index, llm_name, top_k=5):\n",
    "    \"\"\"\n",
    "    makes sure we get the correct format and returns it\n",
    "    :param query_text: str, text to analyze \n",
    "    :param index: index object, index to retrieve similar examples from.\n",
    "    :param llm_name: str, name of llm to use, has to be either \"OpenAi\" or \"DeepSeek\".\n",
    "    :param top_k: int, number of éxamples to compare\n",
    "    :return: dictionary of predicted labels\n",
    "    \"\"\"\n",
    "    response = extract_dict_from_response(retrieve_with_llm(query_text, index, llm_name, top_k))\n",
    "    \n",
    "    while not response[0]:\n",
    "        response = extract_dict_from_response(retrieve_with_llm(query_text, index, llm_name, top_k))\n",
    "    \n",
    "    return response[1]\n",
    "        "
   ],
   "id": "2ae6e44995b4b088",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T16:50:23.755886Z",
     "start_time": "2025-08-29T16:50:23.750654Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_rag_api_pipeline(df, test_texts, model_name, index_name, llm_name, top_k=5):\n",
    "    \"\"\"\n",
    "    Complete RAG pipeline using LlamaIndex\n",
    "    :param df: reference dataframe with text elements and labels\n",
    "    :param test_texts: list of test texts\n",
    "    :param model_name: str indicating which model to use for embeddings. If 'Bert', uses \"dbmdz/bert-base-german-uncased\", else \"intfloat/multilingual-e5-large\"\n",
    "    :param index_name: str, name of index to be used, either VectorStoreIndex or KeywordStoreIndex\n",
    "    :param llm_name: str, name of llm to use, has to be either \"OpenAi\" or \"DeepSeek\".\n",
    "    :param top_k: int, number of similar examples\n",
    "    :return: dataframe  \n",
    "    \"\"\"\n",
    "    print(\"Step 1: Preparing training nodes...\")\n",
    "    training_nodes = prepare_training_nodes(df)\n",
    "    \n",
    "    print(\"Step 2: Creating vector index...\")\n",
    "    if index_name == 'VectorStoreIndex':\n",
    "        index = create_reload_vector_index(training_nodes, model_name)\n",
    "    elif index_name == 'KeywordStoreIndex':\n",
    "        index = create_reload_keyword_index(training_nodes)\n",
    "    else:\n",
    "        print('no valid index')\n",
    "    \n",
    "    print(\"Step 3: Making predictions...\")\n",
    "    predictions = []\n",
    "    \n",
    "    for test_text in test_texts:\n",
    "        prediction = get_proper_response(test_text, index, llm_name, top_k)\n",
    "        prediction_dict = dict()\n",
    "        prediction_dict['text'] = test_text\n",
    "        prediction_dict.update(prediction)\n",
    "        predictions.append(prediction_dict)\n",
    "    \n",
    "    return pd.DataFrame(predictions, columns=predictions[0].keys())"
   ],
   "id": "d5b3a1199a44d1ec",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Let's test",
   "id": "b49628ce81ff9b1c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# First DeepSeeK",
   "id": "40d60c2867a1ab8e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if run_this: #all of this cost less than 0.5$ and took less than 90min\n",
    "    prds_Bert_VSI_DS_5 = run_rag_api_pipeline(train_df, test_data, 'Bert', 'VectorStoreIndex', 'DeepSeek', top_k=5)\n",
    "    prds_Bert_VSI_DS_10 = run_rag_api_pipeline(train_df, test_data, 'Bert', 'VectorStoreIndex', 'DeepSeek', top_k=10) \n",
    "    prds_Bert_VSI_DS_20 = run_rag_api_pipeline(train_df, test_data, 'Bert', 'VectorStoreIndex', 'DeepSeek', top_k=20)\n",
    "    prds_e5_VSI_DS_5 = run_rag_api_pipeline(train_df, test_data, 'e5', 'VectorStoreIndex', 'DeepSeek', top_k=5)\n",
    "    prds_e5_VSI_DS_10 = run_rag_api_pipeline(train_df, test_data, 'e5', 'VectorStoreIndex', 'DeepSeek', top_k=10)\n",
    "    prds_e5_VSI_DS_20 = run_rag_api_pipeline(train_df, test_data, 'e5', 'VectorStoreIndex', 'DeepSeek', top_k=20) \n",
    "    prds_keyword_DS_5 = run_rag_api_pipeline(train_df, test_data, '', 'KeywordStoreIndex', 'DeepSeek', top_k=5) \n",
    "    prds_keyword_DS_10 = run_rag_api_pipeline(train_df, test_data, '', 'KeywordStoreIndex', 'DeepSeek', top_k=10)\n",
    "    prds_kewyowrd_DS_20 = run_rag_api_pipeline(train_df, test_data, '', 'KeywordStoreIndex', 'DeepSeek', top_k=20)\n",
    "    deepseek = [prds_Bert_VSI_DS_5, prds_Bert_VSI_DS_10, prds_Bert_VSI_DS_20, prds_e5_VSI_DS_5, prds_e5_VSI_DS_10, prds_e5_VSI_DS_20, prds_keyword_DS_5, prds_keyword_DS_10, prds_kewyowrd_DS_20]"
   ],
   "id": "e94c8bfc89b01de1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T12:47:19.463545Z",
     "start_time": "2025-08-29T12:47:19.298757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for df in deepseek:\n",
    "    compute_f1(dev_df.iloc[:100], df)\n",
    "    print('\\n')"
   ],
   "id": "2a49bcb907f3e43b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev set F1 score Bin Maj: 0.74512\n",
      "Dev set F1 score Bin One: 0.8197839135654261\n",
      "Dev set F1 score Bin All: 0.8675411446818964\n",
      "Dev set F1 score Multi Maj: 0.6296413975279106\n",
      "Dev set F1 score Disagree Bin: 0.753844544408411\n",
      "\n",
      "\n",
      "Dev set F1 score Bin Maj: 0.7827267824398664\n",
      "Dev set F1 score Bin One: 0.8197839135654261\n",
      "Dev set F1 score Bin All: 0.88\n",
      "Dev set F1 score Multi Maj: 0.666645189435887\n",
      "Dev set F1 score Disagree Bin: 0.713521275472495\n",
      "\n",
      "\n",
      "Dev set F1 score Bin Maj: 0.801303635768097\n",
      "Dev set F1 score Bin One: 0.7792948717948718\n",
      "Dev set F1 score Bin All: 0.8693333333333334\n",
      "Dev set F1 score Multi Maj: 0.6964141414141415\n",
      "Dev set F1 score Disagree Bin: 0.6863054187192118\n",
      "\n",
      "\n",
      "Dev set F1 score Bin Maj: 0.8183361823361824\n",
      "Dev set F1 score Bin One: 0.7538310893512852\n",
      "Dev set F1 score Bin All: 0.8619780219780221\n",
      "Dev set F1 score Multi Maj: 0.6897341628959276\n",
      "Dev set F1 score Disagree Bin: 0.6540350877192982\n",
      "\n",
      "\n",
      "Dev set F1 score Bin Maj: 0.8001099764336214\n",
      "Dev set F1 score Bin One: 0.7314614121510672\n",
      "Dev set F1 score Bin All: 0.8323349810991567\n",
      "Dev set F1 score Multi Maj: 0.6616666666666666\n",
      "Dev set F1 score Disagree Bin: 0.6129276348713841\n",
      "\n",
      "\n",
      "Dev set F1 score Bin Maj: 0.828303934871099\n",
      "Dev set F1 score Bin One: 0.7408093914118011\n",
      "Dev set F1 score Bin All: 0.8694567663130826\n",
      "Dev set F1 score Multi Maj: 0.6775624947157795\n",
      "Dev set F1 score Disagree Bin: 0.64\n",
      "\n",
      "\n",
      "Dev set F1 score Bin Maj: 0.8099821746880571\n",
      "Dev set F1 score Bin One: 0.7672870249017038\n",
      "Dev set F1 score Bin All: 0.8341621621621621\n",
      "Dev set F1 score Multi Maj: 0.6647725563909773\n",
      "Dev set F1 score Disagree Bin: 0.6654750402576489\n",
      "\n",
      "\n",
      "Dev set F1 score Bin Maj: 0.800803186193163\n",
      "Dev set F1 score Bin One: 0.716040404040404\n",
      "Dev set F1 score Bin All: 0.8341621621621621\n",
      "Dev set F1 score Multi Maj: 0.6536968758795383\n",
      "Dev set F1 score Disagree Bin: 0.6157612300271329\n",
      "\n",
      "\n",
      "Dev set F1 score Bin Maj: 0.8191471215351812\n",
      "Dev set F1 score Bin One: 0.7145454545454545\n",
      "Dev set F1 score Bin All: 0.8403686635944699\n",
      "Dev set F1 score Multi Maj: 0.666403349108118\n",
      "Dev set F1 score Disagree Bin: 0.6020808323329332\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T12:47:22.962190Z",
     "start_time": "2025-08-29T12:47:22.831670Z"
    }
   },
   "cell_type": "code",
   "source": "find_best_model(dev_df.iloc[:100], deepseek)",
   "id": "403d82fcfb3a369e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best performing model is Bert_VSI_10\n",
      "Dev set F1 score Bin Maj: 0.7827267824398664\n",
      "Dev set F1 score Bin One: 0.8197839135654261\n",
      "Dev set F1 score Bin All: 0.88\n",
      "Dev set F1 score Multi Maj: 0.666645189435887\n",
      "Dev set F1 score Disagree Bin: 0.713521275472495\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Now OpenAI",
   "id": "8d2c25ff0666f238"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if run_this:\n",
    "    prds_Bert_VSI_OA_5 = run_rag_api_pipeline(train_df, test_data, \"Bert\", 'VectorStoreIndex', 'OpenAI',  top_k=5)\n",
    "    prds_Bert_VSI_OA_10 = run_rag_api_pipeline(train_df, test_data, \"Bert\",'VectorStoreIndex', 'OpenAI',top_k=10)\n",
    "    prds_Bert_VSI_OA_20 = run_rag_api_pipeline(train_df, test_data, \"Bert\", 'VectorStoreIndex', 'OpenAI', top_k=20)\n",
    "    prds_e5_VSI_OA_5 = run_rag_api_pipeline(train_df, test_data, \"e5\", 'VectorStoreIndex','OpenAI',  top_k=5)\n",
    "    prds_e5_VSI_OA_10 = run_rag_api_pipeline(train_df, test_data, \"e5\", 'VectorStoreIndex','OpenAI', top_k=10)\n",
    "    prds_e5_VSI_OA_20 = run_rag_api_pipeline(train_df, test_data, \"e5\", 'VectorStoreIndex','OpenAI', top_k=20)\n",
    "    prds_keyword_OA_5 = run_rag_api_pipeline(train_df, test_data, \"\", 'KeywordStoreIndex','OpenAI',top_k=5)\n",
    "    prds_keyword_OA_10 = run_rag_api_pipeline(train_df, test_data, \"\", 'KeywordStoreIndex','OpenAI', top_k=10)\n",
    "    prds_kewyowrd_OA_20 = run_rag_api_pipeline(train_df, test_data, \"\", 'KeywordStoreIndex','OpenAI',top_k=20)\n",
    "    openai = [prds_Bert_VSI_OA_5, prds_Bert_VSI_OA_10, prds_Bert_VSI_OA_20, prds_e5_VSI_OA_5, prds_e5_VSI_OA_10, prds_e5_VSI_OA_20, prds_keyword_OA_5, prds_keyword_OA_10, prds_kewyowrd_OA_20]"
   ],
   "id": "624d6dca122f74da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T17:29:46.371474Z",
     "start_time": "2025-08-29T17:29:46.167893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for df in openai:\n",
    "    compute_f1(dev_df.iloc[:100], df)\n",
    "    print('\\n')"
   ],
   "id": "6053b043b8e760bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev set F1 score Bin Maj: 0.7413839708068659\n",
      "Dev set F1 score Bin One: 0.6660726274031126\n",
      "Dev set F1 score Bin All: 0.8619780219780221\n",
      "Dev set F1 score Multi Maj: 0.6910900745840505\n",
      "Dev set F1 score Disagree Bin: 0.6085714285714287\n",
      "\n",
      "\n",
      "Dev set F1 score Bin Maj: 0.7484918495700167\n",
      "Dev set F1 score Bin One: 0.676883116883117\n",
      "Dev set F1 score Bin All: 0.907985347985348\n",
      "Dev set F1 score Multi Maj: 0.6943574990410433\n",
      "Dev set F1 score Disagree Bin: 0.632291543814129\n",
      "\n",
      "\n",
      "Dev set F1 score Bin Maj: 0.7342730953257268\n",
      "Dev set F1 score Bin One: 0.708684343179756\n",
      "Dev set F1 score Bin All: 0.8466968325791855\n",
      "Dev set F1 score Multi Maj: 0.6893650793650794\n",
      "Dev set F1 score Disagree Bin: 0.6288284747243149\n",
      "\n",
      "\n",
      "Dev set F1 score Bin Maj: 0.6612087098207674\n",
      "Dev set F1 score Bin One: 0.6492613807657522\n",
      "Dev set F1 score Bin All: 0.8669738863287252\n",
      "Dev set F1 score Multi Maj: 0.6627702927478376\n",
      "Dev set F1 score Disagree Bin: 0.5911940459497358\n",
      "\n",
      "\n",
      "Dev set F1 score Bin Maj: 0.6088203712225801\n",
      "Dev set F1 score Bin One: 0.619542352468888\n",
      "Dev set F1 score Bin All: 0.8466968325791855\n",
      "Dev set F1 score Multi Maj: 0.6539612403100774\n",
      "Dev set F1 score Disagree Bin: 0.5858259773013872\n",
      "\n",
      "\n",
      "Dev set F1 score Bin Maj: 0.6612087098207674\n",
      "Dev set F1 score Bin One: 0.6501050945851266\n",
      "Dev set F1 score Bin All: 0.8238297872340425\n",
      "Dev set F1 score Multi Maj: 0.6688604459124692\n",
      "Dev set F1 score Disagree Bin: 0.5579831932773109\n",
      "\n",
      "\n",
      "Dev set F1 score Bin Maj: 0.7000054061359643\n",
      "Dev set F1 score Bin One: 0.6201520608243297\n",
      "Dev set F1 score Bin All: 0.8466968325791855\n",
      "Dev set F1 score Multi Maj: 0.6798109243697479\n",
      "Dev set F1 score Disagree Bin: 0.6066666666666667\n",
      "\n",
      "\n",
      "Dev set F1 score Bin Maj: 0.6509333333333334\n",
      "Dev set F1 score Bin One: 0.6501050105010501\n",
      "Dev set F1 score Bin All: 0.8466968325791855\n",
      "Dev set F1 score Multi Maj: 0.6664285714285714\n",
      "Dev set F1 score Disagree Bin: 0.615997489277121\n",
      "\n",
      "\n",
      "Dev set F1 score Bin Maj: 0.7043900513225424\n",
      "Dev set F1 score Bin One: 0.6001600640256102\n",
      "Dev set F1 score Bin All: 0.8466968325791855\n",
      "Dev set F1 score Multi Maj: 0.6575\n",
      "Dev set F1 score Disagree Bin: 0.5463808322824716\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-29T17:29:46.608337Z",
     "start_time": "2025-08-29T17:29:46.437240Z"
    }
   },
   "cell_type": "code",
   "source": "find_best_model(dev_df.iloc[:100], openai)",
   "id": "8b43dab1259675f8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best performing model is Bert_VSI_10\n",
      "Dev set F1 score Bin Maj: 0.7484918495700167\n",
      "Dev set F1 score Bin One: 0.676883116883117\n",
      "Dev set F1 score Bin All: 0.907985347985348\n",
      "Dev set F1 score Multi Maj: 0.6943574990410433\n",
      "Dev set F1 score Disagree Bin: 0.632291543814129\n"
     ]
    }
   ],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
