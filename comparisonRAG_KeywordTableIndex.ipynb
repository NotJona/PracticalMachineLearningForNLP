{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Let us also check what RAG can do for this project - KeywordTableIndex Version",
   "id": "190d947f4928b2c3"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-08-28T10:16:31.345829Z",
     "start_time": "2025-08-28T10:16:20.711031Z"
    }
   },
   "source": "!pip install python-dotenv pandas llama-index langchain langchain-community llama-index-embeddings-langchain  sentence-transformers llama-index-llms-openai",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: llama-index in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (0.12.52)\n",
      "Requirement already satisfied: langchain in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: llama-index-embeddings-langchain in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (0.3.0)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (5.1.0)\n",
      "Requirement already satisfied: llama-index-llms-openai in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (0.4.7)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from pandas) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: llama-index-agent-openai<0.5,>=0.4.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from llama-index) (0.4.12)\n",
      "Requirement already satisfied: llama-index-cli<0.5,>=0.4.2 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from llama-index) (0.4.4)\n",
      "Requirement already satisfied: llama-index-core<0.13,>=0.12.52.post1 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from llama-index) (0.12.52.post1)\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.4,>=0.3.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from llama-index) (0.8.0)\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.6,>=0.5.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from llama-index) (0.5.3)\n",
      "Requirement already satisfied: llama-index-program-openai<0.4,>=0.3.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from llama-index) (0.3.2)\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.4,>=0.3.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from llama-index) (0.3.1)\n",
      "Requirement already satisfied: llama-index-readers-file<0.5,>=0.4.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from llama-index) (0.4.8)\n",
      "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from llama-index) (0.4.0)\n",
      "Requirement already satisfied: nltk>3.8.1 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from llama-index) (3.9.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from langchain) (0.3.74)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from langchain) (0.3.9)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from langchain) (0.4.16)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from langchain) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from langchain-community) (3.12.15)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from langchain-community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from langchain-community) (2.10.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from langchain-community) (0.4.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from sentence-transformers) (4.55.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from sentence-transformers) (2.8.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from sentence-transformers) (1.7.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from sentence-transformers) (1.16.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from sentence-transformers) (0.34.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from sentence-transformers) (4.14.1)\n",
      "Requirement already satisfied: openai<2,>=1.81.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from llama-index-llms-openai) (1.97.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from langsmith>=0.1.17->langchain) (3.11.2)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
      "Requirement already satisfied: aiosqlite in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.52.post1->llama-index) (0.21.0)\n",
      "Requirement already satisfied: banks<3,>=2.2.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.52.post1->llama-index) (2.2.0)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.52.post1->llama-index) (1.2.18)\n",
      "Requirement already satisfied: dirtyjson<2,>=1.0.8 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.52.post1->llama-index) (1.0.8)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.52.post1->llama-index) (1.2.0)\n",
      "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.52.post1->llama-index) (1.3.0)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.52.post1->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.52.post1->llama-index) (3.5)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.52.post1->llama-index) (4.3.8)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.52.post1->llama-index) (80.9.0)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.52.post1->llama-index) (0.11.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from llama-index-core<0.13,>=0.12.52.post1->llama-index) (1.17.3)\n",
      "Requirement already satisfied: llama-cloud==0.1.35 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.35)\n",
      "Requirement already satisfied: certifi>=2024.7.4 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from llama-cloud==0.1.35->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2025.8.3)\n",
      "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (4.13.4)\n",
      "Requirement already satisfied: pypdf<6,>=5.1.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (5.9.0)\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from llama-index-readers-file<0.5,>=0.4.0->llama-index) (0.0.26)\n",
      "Requirement already satisfied: llama-parse>=0.5.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.54)\n",
      "Requirement already satisfied: click in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index) (8.2.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from nltk>3.8.1->llama-index) (2025.7.34)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from openai<2,>=1.81.0->llama-index-llms-openai) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from openai<2,>=1.81.0->llama-index-llms-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from openai<2,>=1.81.0->llama-index-llms-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from openai<2,>=1.81.0->llama-index-llms-openai) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: griffe in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from banks<3,>=2.2.0->llama-index-core<0.13,>=0.12.52.post1->llama-index) (1.12.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.5,>=0.4.0->llama-index) (2.7)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.13,>=0.12.52.post1->llama-index) (0.4.0)\n",
      "Requirement already satisfied: llama-cloud-services>=0.6.54 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.54)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jona\\pycharmprojects\\germevalproject\\.venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T14:08:28.690348Z",
     "start_time": "2025-08-28T14:08:24.122202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from llama_index.core import KeywordTableIndex, StorageContext, load_index_from_storage, Settings\n",
    "from llama_index.core.schema import TextNode\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from llama_index.llms.openai import OpenAI "
   ],
   "id": "84f79b35d9824ae9",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T14:08:30.231648Z",
     "start_time": "2025-08-28T14:08:28.697356Z"
    }
   },
   "cell_type": "code",
   "source": "from functions import load_jsonl, combine_data, compute_f1, check_df",
   "id": "50de8955c1bff275",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Global Variables ",
   "id": "7d71b43443fa1ec1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T14:08:30.430606Z",
     "start_time": "2025-08-28T14:08:30.424801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#data\n",
    "train_file_path = Path('data_germeval/train.jsonl')\n",
    "dev_file_path = Path('data_germeval/development.jsonl')\n",
    "\n",
    "#save/load paths\n",
    "save_path = Path(\"keyword_index\")\n",
    "\n",
    "#which openAI model to use\n",
    "llm_model = \"gpt-3.5-turbo\"\n",
    "\n",
    "#do we want to compute the vector index?\n",
    "run_this = True"
   ],
   "id": "af5d131f5b450d93",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Let's load the API",
   "id": "ac9e595dc547c3db"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T14:08:30.458762Z",
     "start_time": "2025-08-28T14:08:30.448493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY_25\")\n",
    "print(f\"API Key loaded: {OPENAI_API_KEY is not None}\")"
   ],
   "id": "256881963620b3ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key loaded: True\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# The usual setup",
   "id": "2acbcddeb778b93"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T14:08:30.865154Z",
     "start_time": "2025-08-28T14:08:30.694255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = load_jsonl(train_file_path)\n",
    "train_data_labeled = combine_data(train_data)\n",
    "train_df = combine_data(train_data, dataframe = True)\n",
    "\n",
    "dev_data = load_jsonl(dev_file_path)\n",
    "dev_data_labeled = combine_data(dev_data)\n",
    "dev_df = combine_data(dev_data, dataframe = True)\n",
    "\n",
    "test_data = [dev_data_labeled[i]['text'] for i in range(100)]"
   ],
   "id": "6bd2644385c0cf23",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# MAIN PART",
   "id": "1942224ab19473a7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Let's get started with KeywordTableIndex",
   "id": "8bc8343154f47fa4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "What happens here? Basically we index our data by keywords. An LLM is used for this purpose and hence, we do need an API key. After the indexing, the resulting keyword table points to the different data. If a new text is queried, the retriever filters out its \"relevant\" words and matches query text and data based on those (via the keyword table).",
   "id": "35341ced82adccc3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The LLM/API key is only used for indexing, not retrieving. The indexing costs about 0.4$.",
   "id": "a759f88a096fbcf5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T14:08:33.893966Z",
     "start_time": "2025-08-28T14:08:33.883562Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_training_nodes(df):\n",
    "    \"\"\"\n",
    "    Prepares our data for indexing.\n",
    "    :param df: dataframe \n",
    "    :return: TextNode object of our dataframe\n",
    "    \"\"\"\n",
    "    training_nodes = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        text_content = f\"\"\"\n",
    "        Example Text: {row['text']}\n",
    "        \"\"\"\n",
    "        \n",
    "        node = TextNode(\n",
    "        text=text_content,\n",
    "        metadata={\n",
    "        'original_text': row['text'],\n",
    "        'bin_maj_label': row['bin_maj_label'],\n",
    "        'bin_one_label': row['bin_one_label'],\n",
    "        'bin_all_label': row['bin_all_label'],\n",
    "        'multi_maj_label': row['multi_maj_label'],\n",
    "        'disagree_bin_label': row['disagree_bin_label'],\n",
    "        'index': index\n",
    "        }\n",
    "        )\n",
    "        training_nodes.append(node)\n",
    "    \n",
    "    return training_nodes"
   ],
   "id": "78925ff4eebf357d",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T14:08:34.384535Z",
     "start_time": "2025-08-28T14:08:34.380656Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_index(load_path):\n",
    "    \"\"\"\n",
    "    Loads precomputed index\n",
    "    :param load_path: str, path to precomputed index\n",
    "    :return: loaded index \n",
    "    \"\"\"\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=load_path)\n",
    "    index = load_index_from_storage(\n",
    "        storage_context, \n",
    "    )\n",
    "    print(f\"Index loaded from {load_path}!\")\n",
    "    return index"
   ],
   "id": "d3df2eb6ce84d235",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T14:08:34.787731Z",
     "start_time": "2025-08-28T14:08:34.780997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_reload_keyword_index(nodes):\n",
    "    \"\"\"\n",
    "    Creates or reloads a vector index using our nodes and LlamaIndex\n",
    "    :param nodes: list of nodes \n",
    "    :return: generated or reloaded index\n",
    "    \"\"\"\n",
    "    llm = OpenAI(api_key=OPENAI_API_KEY, model=llm_model)\n",
    "    \n",
    "    Settings.llm = llm\n",
    "    \n",
    "    if os.path.exists(save_path):\n",
    "        print(\"Loading existing keyword index...\")\n",
    "        storage_context = StorageContext.from_defaults(persist_dir=save_path)\n",
    "        return load_index_from_storage(storage_context)  \n",
    "    else:\n",
    "        print(\"Creating keyword index...\")\n",
    "        index = KeywordTableIndex(nodes)  \n",
    "        \n",
    "        index.storage_context.persist(persist_dir=save_path)\n",
    "        print(f\"Keyword index saved to {save_path}!\")\n",
    "        \n",
    "        return index"
   ],
   "id": "1e17d8e4affbf3f5",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T14:08:35.319438Z",
     "start_time": "2025-08-28T14:08:35.314733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def retrieve_similar_examples(query_text, index, top_k=5):\n",
    "    \"\"\"\n",
    "    Retrieves similar examples using KeywordTableIndex\n",
    "    :param query_text: str, query text\n",
    "    :param index: KeywordTableIndex to use for retrieval\n",
    "    :param top_k: int, number of similar examples\n",
    "    :return: list of similar examples\n",
    "    \"\"\"\n",
    "    # For KeywordTableIndex, just use as_retriever() without special parameters\n",
    "    retriever = index.as_retriever(similarity_top_k=top_k)\n",
    "    similar_nodes = retriever.retrieve(query_text)\n",
    "\n",
    "    results = []\n",
    "    for node in similar_nodes:\n",
    "        results.append({\n",
    "            'text': node.node.text,\n",
    "            'metadata': node.node.metadata,\n",
    "            'keyword_match_score': node.score\n",
    "        })\n",
    "    \n",
    "    return results"
   ],
   "id": "f133078f21714774",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T14:08:35.757738Z",
     "start_time": "2025-08-28T14:08:35.748524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def majority_aggregation(value_list):\n",
    "    \"\"\"\n",
    "    Computes the majority vote of value_list. This makes the most sense as we are dealing with categorical data. \n",
    "    :param value_list: list of values\n",
    "    :return: float\n",
    "    \"\"\"\n",
    "    return Counter(value_list).most_common(1)[0][0]"
   ],
   "id": "62e8d53a002ce805",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T14:08:36.291491Z",
     "start_time": "2025-08-28T14:08:36.284358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_from_similar_examples(similar_examples):\n",
    "    \"\"\"\n",
    "    Predict target value from similar examples\n",
    "    :param similar_examples: list of similar examples\n",
    "    :return: list of predictions\n",
    "    \"\"\"\n",
    "    if not similar_examples:\n",
    "        return None\n",
    "\n",
    "    target_values = [[ex['metadata']['bin_maj_label'] for ex in similar_examples],\n",
    "                     [ex['metadata']['bin_one_label'] for ex in similar_examples],\n",
    "                     [ex['metadata']['bin_all_label'] for ex in similar_examples],\n",
    "                     [ex['metadata']['multi_maj_label'] for ex in similar_examples],\n",
    "                     [ex['metadata']['disagree_bin_label'] for ex in similar_examples]]\n",
    "    \n",
    "    return [majority_aggregation(target_values) for target_values in target_values]\n",
    "        "
   ],
   "id": "f9f9ca996b750712",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T14:08:36.896243Z",
     "start_time": "2025-08-28T14:08:36.882855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def data_to_dataframe(prediction):\n",
    "    \"\"\"\n",
    "    takes the output of run_rag_pipeline and turns it into a pandas dataframe with fitting columns for comparison\n",
    "    :param prediction: list of dictionaries of the form: {'query_text': , 'prediction':, 'num_similar_examples': 'similar_examples': } \n",
    "    :return: dataframe\n",
    "    \"\"\"\n",
    "    prediction = [{'text': p['query_text'], \n",
    "                'bin_maj_label': p['prediction'][0],\n",
    "                'bin_one_label': p['prediction'][1],\n",
    "                'bin_all_label': p['prediction'][2], \n",
    "                'multi_maj_label':p['prediction'][3],\n",
    "                'disagree_bin_label': p['prediction'][4],\n",
    "                'similar_text_1': p['similar_examples'][0]['text'],\n",
    "                'similar_text_2': p['similar_examples'][-1]['text']} for p in prediction]\n",
    "    return pd.DataFrame(prediction, columns=prediction[0].keys())"
   ],
   "id": "dd86a1105eca2b5f",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T14:08:37.497945Z",
     "start_time": "2025-08-28T14:08:37.483139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_rag_pipeline(df, test_texts, top_k=5):\n",
    "    \"\"\"\n",
    "    Complete RAG pipeline using LlamaIndex\n",
    "    :param df: reference dataframe with text elements and labels\n",
    "    :param test_texts: list of test texts\n",
    "    :param top_k: int, number of similar examples\n",
    "    :return: dataframe  \n",
    "    \"\"\"\n",
    "    print(\"Step 1: Preparing training nodes...\")\n",
    "    training_nodes = prepare_training_nodes(df)\n",
    "    \n",
    "    print(\"Step 2: Creating/Reloading vector index...\")\n",
    "    index = create_reload_keyword_index(training_nodes)\n",
    "    \n",
    "    print(\"Step 3: Making predictions...\")\n",
    "    predictions = []\n",
    "    \n",
    "    for test_text in test_texts:\n",
    "        similar_examples = retrieve_similar_examples(test_text, index, top_k)\n",
    "        \n",
    "        # if no similar examples are found\n",
    "        if not similar_examples: \n",
    "            print(f\"    No similar examples found for: {test_text[:50]}...\")\n",
    "            predictions.append({'query_text': test_text, \n",
    "                                 'prediction': [None, None, None, None, None],\n",
    "                                 'similar_examples': [{'text':None}, {'text':None}]})\n",
    "        else:\n",
    "            prediction = predict_from_similar_examples(similar_examples)\n",
    "            predictions.append({\n",
    "                'query_text': test_text,\n",
    "                'prediction': prediction,\n",
    "                'num_similar_examples': len(similar_examples),\n",
    "                'similar_examples': similar_examples[:2] \n",
    "            })\n",
    "    #print(predictions)\n",
    "    return data_to_dataframe(predictions)"
   ],
   "id": "593a3bc13448be8",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Let's see how well the indexing worked:",
   "id": "fd4c050d05240803"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T12:22:37.853608Z",
     "start_time": "2025-08-28T11:30:42.636544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if run_this:\n",
    "    test_index = run_rag_pipeline(train_df,test_data[:10])"
   ],
   "id": "e01380f48fb0a66b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Preparing training nodes...\n",
      "Step 2: Creating/Reloading vector index...\n",
      "Creating keyword index...\n",
      "Keyword index saved to keyword_index!\n",
      "Step 3: Making predictions...\n"
     ]
    }
   ],
   "execution_count": 136
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T12:25:00.906854Z",
     "start_time": "2025-08-28T12:25:00.885101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for index, row in test_index.iterrows():\n",
    "    print('Text')\n",
    "    print(row['text'])\n",
    "    print('\\n Retrieved \"similar\" ones')\n",
    "    print(row['similar_text_1'])\n",
    "    print(row['similar_text_2'])"
   ],
   "id": "363eb474d7c0f32f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text\n",
      "Das ist ein richtig gutes Portrait von Greta!\n",
      "\n",
      " Retrieved \"similar\" ones\n",
      "\n",
      "        Example Text: Wird sich an Bord gscheit durchputzen lassen die Liebe Greta\n",
      "        \n",
      "\n",
      "        Example Text: Die Wahrscheinlichkeit dass ich irgendwann mal in Greta stecke ist wesentlich größer als dass Greta in mir stecken kann.\n",
      "        \n",
      "Text\n",
      "bei den dort üblichen kalaschnikows wärs eher eine zahl mit ein paar nullen mehr ...\n",
      "\n",
      " Retrieved \"similar\" ones\n",
      "\n",
      "        Example Text: warum seid ihr solche kleingeister? dann sinds 17,50 sekunden oder auch zwanzig... die zahl stand metaphorisch dafür wie klein die stadt ist aber ihr begriffsbehinderten hängt euch bei den kilometern auf... alter wie eng kann der horizont sein oder wie klein muss das selbstbewusstsein sein wenn man sich über sowas aufregt oder profiliert...\n",
      "        \n",
      "\n",
      "        Example Text: Warum fahren Frauen immer noch auf solche Events? Und nein, nicht die Frauen sind schuld - aber warum muss man sich immer noch, bei solchen Events diesem Risiko aussetzen inkl. Komasaufen und Drogen. Es ist seit langem mehr als bekannt, was auf SummerSplash und X-Jam abgeht, das Wissen ist vorhanden und trotzdem fahren junge Frauen in großer Zahl dort hin.\n",
      "        \n",
      "Text\n",
      "Nein.Es war eine Single-Börse,  die den ganzen deutschsprachigen Raum umfasst- ich glaube Lovescout. Hat aber nur zu virtuellen Verbindungen geführt- eben weil die betreffenden Männer hunderte Kilometer von mir entfernt gewohnt haben.Und dann die Websingles mit 2 wirklichen Volltreffern.Und dort ist es mittlerweile ähnlich wie auf Facebook: Es treiben sich hauptsächlich ältere Semester dort herum.Ich hab auch die Geschichte mit psychologischem Persönlichkeitsprofil und Matching Points probiert- das war bei Lovescout gegen eine Gebühr möglich.Der Algorithmus hat mir nur Partnervorschläge gemacht, die mich in genau Null Kategorien angesprochen haben.\n",
      "\n",
      " Retrieved \"similar\" ones\n",
      "\n",
      "        Example Text: Die kinderlose Single wird Kinder bekommen.\n",
      "        \n",
      "\n",
      "        Example Text: wenn ich das richtig sehe... ...und wenn ich single bin ist es ganz ok wenn ein linker eine gschmackige Freundin hat, dass ich da mal lüstern drüber stiege - denn wenn ich nichts hab solls mir jemand der was hat geben.\n",
      "        \n",
      "Text\n",
      "Weil die Welt heute ein Dorf ist.\n",
      "\n",
      " Retrieved \"similar\" ones\n",
      "\n",
      "        Example Text: 1) Führungsverhalten von Männern und Frauen ist unterschiedlich2) Führungsverhalten in Demokratien und in Diktaturen ist ebenfalls     unterschiedlich3) Führungsverhalten in religiös dominierten Gesellschaften unterscheidet sich gegenüber nicht religiös dominierten Gesellschaften .. 4) Militärisches Führungsverhalten unterscheidet sich drastisch von zivilen Führungsverhalten Mit Diversifikationskriterien hat man noch nie ein Unternehmen zum Erfolg, odereine Armee zum Sieg geführt :-)Aber ich sehe schon ein, das Diversifikationskriterien ein gefundenes Fressen für Berater und Aufseher sind .. und die nächste Sau ist, die durchs Dorf getrieben wird :-)\n",
      "        \n",
      "\n",
      "        Example Text: Ok, Boomer. Wir werden dich nicht vermissen, {USER}. Die Welt kommt auch gut ohne dich aus. Und auch nach dir werden wir weiter gut zurechtkommen.\n",
      "        \n",
      "Text\n",
      "Wenn sich einer psychische Gewalt gefallen lässt, vor der man fliehen kann, da ja keine Bedrohung von Leib und Leben besteht wie bei körperlicher, liegt es im Ermessen des Mannes, ob er das will oder nicht. Ach wie liebe ich die Jammereien von euch Lappen, nur weil ihr zu feige und schwach seid, diese Partnerinnen zu verlassen, euch eine eigene Wohnung zu nehmen, ein eigenes Leben zu beginnen. Das kann eine Frau, die körperlich bedroht wird, nämlich NICHT machen, verstehst du?  Und ja, Männer begehen mehr Selbstmorde, weil sie gewaltbereiter (auch gegen sich selbst) sind und eben charakterlich schwächer, weniger aushalten (müssen) als Frauen. Da können Frauen nix dafür!\n",
      "\n",
      " Retrieved \"similar\" ones\n",
      "\n",
      " Bursche weint - Lehrer interessiert es nicht, Note bleibt, Mitschüler lachen ihn aus!egen ist, aber ich weiß aus eigener Erfahrung auch, welche enormen psychischen Druck Frauen auf einen ausüben können, bloß, wenn da drüber jammerst, wirst als \"Weichei\" und \"Versager\" abgestempelt... Frau \"jahrelang psychische Gewalt\" angewandt hat?\n",
      "        \n",
      "\n",
      "        Example Text: {USER}: warum zählt bei ihnen psychische gewalt im hause hinter verschlossenen türen nicht zu häuslicher gewalt? sagt ihnen der begriff weiblicher narzissmus etwas?\n",
      "        \n",
      "Text\n",
      "Primtivlinge wie dich gibts glücklicherweise immer weniger, und die, die es gibt, wandern schön langsam in die Anstalten, in die sie gehören...\n",
      "\n",
      " Retrieved \"similar\" ones\n",
      "\n",
      "        Example Text: Vor allem wenn Frauen bevorzugt werden. Z.B. beim Aufnahmetest fürs Medizinstudium.   Wundert mich nicht, dass sich aber bisher keine beschwert hat, dass man ihnen so offensichtlich Dummheit unterstellt indem man weniger Leistung fordert.          Und nebenbei: Arbeitet man Teilzeit verdient man auch weniger.\n",
      "        \n",
      "\n",
      "        Example Text: mit wievielen Nationalspielern hatte Jogi Löw schon Sex? Rot: mehr als 3 Grün: weniger als 3\n",
      "        \n",
      "Text\n",
      "wenn Greta eine junge Frau sein soll, dann hat sie gefälligst ein bisserl busen zu haben, sonst ist sie ein kind, keine frau...\n",
      "\n",
      " Retrieved \"similar\" ones\n",
      "\n",
      "        Example Text: Sie haben immer noch nicht begriffen, dass ich es völlig geschlechtsneutral meine. Ich habe Ihnen die \"alte\" Rollenverteilung unterstellt, Ihrem Alter entsprechen wahrscheinlich zurecht. 2 Menschen kommen zusammen, völlig egal welchen Geschlechts und müssen sich gefälligst selbst drauf einigen wer welche Aufgaben übernimmt. Da braucht es keinen Staat dazu, abgesehen von einer ständig weniger werdenden Handvoll unselbstständiger Hascherln. Was halten Sie vom Selbstbewusstsein und Selbständigkeit einer heutigen jungen Frau, die sind nicht mehr die Mauerblümchen Ihrer Vergangenheit. Die Welt hat sich weiterbewegt...\n",
      "        \n",
      "\n",
      "        Example Text: Nicht lachen, aber das kann als Einkommen schon hin kommen, wenn du eine junge Frau bist, die ihre Reize einzusetzen weiß.\n",
      "        \n",
      "Text\n",
      "Habe ich nie behauptet, dass sie von einem Bett ins andere hüpfen .. Sie haben von 40 jährigen Ziegen gesprochen die sich ganz ohne blaue Pillen mit 50 jährigen vergnügen und aus der Ziegenrunde herzliche Grüße ausgerichtet ..Da Ziegen in der Regel ja nur um die 20 Jahre alt werden , kann es sich nur um einen Scherz gehandelt haben ..\n",
      "\n",
      " Retrieved \"similar\" ones\n",
      "\n",
      "        Example Text: Mich würde interessieren, wie viele Deppen es gibt, die dann mit einer 50-jährigen frustrierten, alten Schachtel (außer die hatten vorher eine langjährige Beziehung) bewusst ein Kind produzieren, um dann Alimente zu zahlen.  Außer die sind 70+, dann ist ehe schon alles wurscht.\n",
      "        \n",
      "\n",
      "        Example Text: Das Ärzteteam inkl. Pflegepersonal ist mit Testen beschäftigtoh Mann, dagegen gibts Pillen\n",
      "        \n",
      "Text\n",
      "Ich arbeite lieber mit Männern zusammen, weil die nicht so viel Förderung, Unterstützung und Verständnis brauchen, in schwierigen Zeiten jedenfalls. Kann Frau bitte einfach Informatik studieren ohne zu nerven? Ich habe das Gefühl, es mit Schwerbehinderten zu tun zu haben.\n",
      "\n",
      " Retrieved \"similar\" ones\n",
      "\n",
      "        Example Text: Kann ich nur bestätigen, ohne Mädels wäre es bei uns im Büro auch um einiges \"fader\" und das hat nichts mit Sexismus zu tun... Ich meine wenn eine Kollegin männliche unterstützung brauchen könnte, ist man hier bei uns auch gerne eine Hilfe und es wäre niemanden von uns jemals eingefallen, sowas als sexismus hinzustellen. Gibt eben Dinge die können durchschnittlich Frauen besser  und eben andere Dinge können Männer von Natur aus besser - was soll da verwerflich sein?Verklagt doch die Evolution, aber die hat sich dabei schon was gedacht, wegen Familie und so warats, aber ihr eh wissen ;)\n",
      "        \n",
      "\n",
      "        Example Text: Gibt doch eine ganz einfache Lösung. In Zukunft machen Frauen den Grundwehrdienst und solche Einsätze und Männer beurteilen dann, ob sich die Damen immer 100% korrekt und professionell verhalten.  Keine Lust? .Dann würd ich einfach mal vorschlagen, mich bei den Burschen, die das professionell gemacht haben zu bedanken und bei den 2-3 die mal daneben gehauen haben ein Mindestmaß an Verständnis zu zeigen. Sonst: selber machen!\n",
      "        \n",
      "Text\n",
      "Stimmt - dort will man auch keine Frauen einstellen.\n",
      "\n",
      " Retrieved \"similar\" ones\n",
      "\n",
      "        Example Text: Ja, Frauen werden auch in Beziehungen missbraucht, manche werden dabei sogar umgebracht. Solche Beziehungen gibt auch bei Promis, oder gerade dort und wenn - was sagt das über die anwürfe der dame?\n",
      "        \n",
      "\n",
      "        Example Text: Das Erscheinungsbild der Männer unterliegt dem Gesetz. Das der Frauen ist eine einfache Verordnung.\n",
      "        \n"
     ]
    }
   ],
   "execution_count": 138
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The keyword search went well. However, with KeywordTableIndex the most \"similar\" comments, are often very different in actual meaning. As we use the majority vote of the \"most similar\" comments for prediction, I would expect KeywordTableIndex to perform worse than VectorScoreIndex.",
   "id": "2b16cbdfbdc3f346"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Let's make some predictions and evaluate them!",
   "id": "2718c4396b5a2ad4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T14:13:20.671003Z",
     "start_time": "2025-08-28T14:08:42.292046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if run_this:\n",
    "    test_index_5 = run_rag_pipeline(train_df,test_data,top_k=5)\n",
    "    test_index_10 = run_rag_pipeline(train_df,test_data,top_k=10)\n",
    "    test_index_20 = run_rag_pipeline(train_df,test_data,top_k=20)"
   ],
   "id": "b3f8434d853401d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Preparing training nodes...\n",
      "Step 2: Creating/Reloading vector index...\n",
      "Loading existing keyword index...\n",
      "Loading llama_index.core.storage.kvstore.simple_kvstore from keyword_index\\docstore.json.\n",
      "Loading llama_index.core.storage.kvstore.simple_kvstore from keyword_index\\index_store.json.\n",
      "Step 3: Making predictions...\n",
      "    No similar examples found for: Kardinal schönbirn von östarreich ist mörderisch v...\n",
      "    No similar examples found for: Wie wär's mit Vizespasti?...\n",
      "Step 1: Preparing training nodes...\n",
      "Step 2: Creating/Reloading vector index...\n",
      "Loading existing keyword index...\n",
      "Loading llama_index.core.storage.kvstore.simple_kvstore from keyword_index\\docstore.json.\n",
      "Loading llama_index.core.storage.kvstore.simple_kvstore from keyword_index\\index_store.json.\n",
      "Step 3: Making predictions...\n",
      "    No similar examples found for: Kardinal schönbirn von östarreich ist mörderisch v...\n",
      "    No similar examples found for: Wie wär's mit Vizespasti?...\n",
      "Step 1: Preparing training nodes...\n",
      "Step 2: Creating/Reloading vector index...\n",
      "Loading existing keyword index...\n",
      "Loading llama_index.core.storage.kvstore.simple_kvstore from keyword_index\\docstore.json.\n",
      "Loading llama_index.core.storage.kvstore.simple_kvstore from keyword_index\\index_store.json.\n",
      "Step 3: Making predictions...\n",
      "    No similar examples found for: Kardinal schönbirn von östarreich ist mörderisch v...\n",
      "    No similar examples found for: Wie wär's mit Vizespasti?...\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T14:13:20.739428Z",
     "start_time": "2025-08-28T14:13:20.685544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('with k = 5')\n",
    "compute_f1(*check_df(dev_df.iloc[:100], test_index_5))\n",
    "print('with k = 10')\n",
    "compute_f1(*check_df(dev_df.iloc[:100], test_index_10))\n",
    "print('with k = 20')\n",
    "compute_f1(*check_df(dev_df.iloc[:100], test_index_20)) #best model"
   ],
   "id": "f6246f7192dd092f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with k = 5\n",
      "number of removed entries: 2\n",
      "Dev set F1 score Bin Maj: 0.7132726296260131\n",
      "Dev set F1 score Bin One: 0.6261293523751996\n",
      "Dev set F1 score Bin All: 0.8308490246927499\n",
      "Dev set F1 score Multi Maj: 0.6594396794862524\n",
      "Dev set F1 score Disagree Bin: 0.5827975025626688\n",
      "with k = 10\n",
      "number of removed entries: 2\n",
      "Dev set F1 score Bin Maj: 0.6991540802367459\n",
      "Dev set F1 score Bin One: 0.6261293523751996\n",
      "Dev set F1 score Bin All: 0.8246031746031747\n",
      "Dev set F1 score Multi Maj: 0.6594396794862524\n",
      "Dev set F1 score Disagree Bin: 0.5737071966580164\n",
      "with k = 20\n",
      "number of removed entries: 2\n",
      "Dev set F1 score Bin Maj: 0.7232339089481946\n",
      "Dev set F1 score Bin One: 0.616755655125068\n",
      "Dev set F1 score Bin All: 0.8308490246927499\n",
      "Dev set F1 score Multi Maj: 0.6665495539533179\n",
      "Dev set F1 score Disagree Bin: 0.5957751521661295\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Conclusion\n",
   "id": "f04519d8aebc24e5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Predictions get better with increasing number of similar examples retrieved.",
   "id": "8159bfa657ba9e73"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As expected KeywordTableIndex performs worse than VectorScoreIndex and \"comparisonAPI.ipynb\". Considering it also cost money (which VectorScoreIndex did not), KeywordTableIndex with majority vote seems not to be the best tool for handling this task.   ",
   "id": "f7c3fc71383f50ea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "KeywordTableIndex would most likely profit from a combined approach. First using this index to retrieve relevant examples and then sending them via a prompt template to an LLM to predict the outcome. This will be my last step.",
   "id": "4c82fc098996bf76"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
