{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Let us also check what RAG can do for this project - VectorStoreIndex Version",
   "id": "60cf76461b7ca953"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Thing is, with the API alone, not all examples could be processed (prompt would have been too big). RAG could solve this problem, as it enables us to scan all examples from the training data and retrieve the most relevant ones.",
   "id": "f14abea909a80add"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": "!pip install python-dotenv pandas llama-index langchain langchain-community llama-index-embeddings-langchain  sentence-transformers llama-index-llms-openai",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T09:26:57.607782Z",
     "start_time": "2025-08-28T09:26:57.492391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from llama_index.core import VectorStoreIndex, StorageContext, load_index_from_storage\n",
    "from llama_index.core.schema import TextNode\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from collections import Counter\n",
    "from pathlib import Path"
   ],
   "id": "8b1c9ecd75350c2d",
   "outputs": [],
   "execution_count": 151
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T09:26:58.078833Z",
     "start_time": "2025-08-28T09:26:58.061700Z"
    }
   },
   "cell_type": "code",
   "source": "from functions import load_jsonl, combine_data, compute_f1",
   "id": "40501ab782ce2479",
   "outputs": [],
   "execution_count": 152
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Global Variables",
   "id": "2f434779016fcce8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T09:27:05.833912Z",
     "start_time": "2025-08-28T09:27:05.815869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#data\n",
    "train_file_path = Path('data_germeval/train.jsonl')\n",
    "dev_file_path = Path('data_germeval/development.jsonl')\n",
    "\n",
    "#models\n",
    "bert_model = \"dbmdz/bert-base-german-uncased\"\n",
    "multilingual_e5_model = \"intfloat/multilingual-e5-large\"\n",
    "\n",
    "#save/load paths\n",
    "vector_index_bert_path = Path(\"vector_index_BERT\")\n",
    "vector_index_multilingual_e5_path = Path(\"vector_index_multilingual-e5\")\n",
    "\n",
    "#do we want to compute the vector index?\n",
    "run_this = True"
   ],
   "id": "4680592df8e525e4",
   "outputs": [],
   "execution_count": 153
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# The usual setup",
   "id": "99eb85c4fb8299a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T09:27:09.116694Z",
     "start_time": "2025-08-28T09:27:08.584861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = load_jsonl(train_file_path)\n",
    "train_data_labeled = combine_data(train_data)\n",
    "train_df = combine_data(train_data, dataframe = True)\n",
    "\n",
    "dev_data = load_jsonl(dev_file_path)\n",
    "dev_data_labeled = combine_data(dev_data)\n",
    "dev_df = combine_data(dev_data, dataframe = True)\n",
    "\n",
    "test_data = [dev_data_labeled[i]['text'] for i in range(100)]"
   ],
   "id": "e55826622930e068",
   "outputs": [],
   "execution_count": 154
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# MAIN PART",
   "id": "1b04762985ff8db5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Let's get started with VectorStoreIndex",
   "id": "2cbb6ed6845a8d68"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "What is happening here? Basically, we transform our textdata into vector representations. Then, given a new text element, we retrieve the most similar text elements (by comparing vector similarity) and average over the labels of the most similar ones. ",
   "id": "d8bedd7dd0f3788b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "VectorStoreIndex (here) relies on a huggingface model for the embedding. We don't send our data to any LLM for it to predict a label based on the retrieved information. Hence, we don't get input form the LLM (though we might want it, depending on the performance of this code) and no API key is needed.",
   "id": "55c0516df70dc70e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T09:27:11.082208Z",
     "start_time": "2025-08-28T09:27:11.070174Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_training_nodes(df):\n",
    "    \"\"\"\n",
    "    Prepares our data for indexing.\n",
    "    :param df: dataframe \n",
    "    :return: TextNode object of our dataframe\n",
    "    \"\"\"\n",
    "    training_nodes = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        text_content = f\"\"\"\n",
    "        Example Text: {row['text']}\n",
    "        \"\"\"\n",
    "        \n",
    "        node = TextNode(\n",
    "        text=text_content,\n",
    "        metadata={\n",
    "        'original_text': row['text'],\n",
    "        'bin_maj_label': row['bin_maj_label'],\n",
    "        'bin_one_label': row['bin_one_label'],\n",
    "        'bin_all_label': row['bin_all_label'],\n",
    "        'multi_maj_label': row['multi_maj_label'],\n",
    "        'disagree_bin_label': row['disagree_bin_label'],\n",
    "        'index': index\n",
    "        }\n",
    "        )\n",
    "        training_nodes.append(node)\n",
    "    \n",
    "    return training_nodes"
   ],
   "id": "da1c816bbec32b05",
   "outputs": [],
   "execution_count": 155
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T09:27:11.749007Z",
     "start_time": "2025-08-28T09:27:11.737552Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_index(load_path, embed_model):\n",
    "    \"\"\"\n",
    "    Loads precomputed index\n",
    "    :param load_path: str, path to precomputed index\n",
    "    :param embed_model: model to use for embeddings\n",
    "    :return: loaded index \n",
    "    \"\"\"\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=load_path)\n",
    "    index = load_index_from_storage(\n",
    "        storage_context, \n",
    "        embed_model=embed_model\n",
    "    )\n",
    "    print(f\"Index loaded from {load_path}!\")\n",
    "    return index"
   ],
   "id": "9c16a227454055b8",
   "outputs": [],
   "execution_count": 156
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T09:27:12.251358Z",
     "start_time": "2025-08-28T09:27:12.237938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_reload_vector_index(nodes, model):\n",
    "    \"\"\"\n",
    "    Creates or reloads a vector index using our nodes and LlamaIndex\n",
    "    :param nodes: list of nodes \n",
    "    :param model: str, indicates model to use for embeddings\n",
    "    :return: generated or reloaded index\n",
    "    \"\"\"\n",
    "    if model == \"Bert\":\n",
    "        embed_model = HuggingFaceEmbeddings(model_name=bert_model)\n",
    "        save_path = vector_index_bert_path\n",
    "    else:\n",
    "        embed_model = HuggingFaceEmbeddings(model_name=multilingual_e5_model)\n",
    "        save_path = vector_index_multilingual_e5_path\n",
    "        \n",
    "    if os.path.exists(save_path):\n",
    "        print(\"Loading existing index...\")\n",
    "        return load_index(save_path, embed_model)\n",
    "    else:\n",
    "        print(\"Creating index...\")\n",
    "        index = VectorStoreIndex(\n",
    "            nodes,\n",
    "            embed_model=embed_model\n",
    "        )\n",
    "        \n",
    "        index.storage_context.persist(persist_dir=save_path)\n",
    "        print(f\"Index saved to {save_path}!\")\n",
    "        \n",
    "        return index"
   ],
   "id": "696db1415e47adb3",
   "outputs": [],
   "execution_count": 157
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T09:27:12.816140Z",
     "start_time": "2025-08-28T09:27:12.804944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def retrieve_similar_examples(query_text, index, top_k=5):\n",
    "    \"\"\"\n",
    "    Retrieves similar examples using LlamaIndex\n",
    "    :param query_text: str, query text\n",
    "    :param index: index to use to retrieve similar examples\n",
    "    :param top_k: int, number of similar examples\n",
    "    :return: list of similar examples\n",
    "    \"\"\"\n",
    "    retriever = index.as_retriever(similarity_top_k=top_k)\n",
    "    similar_nodes = retriever.retrieve(query_text)\n",
    "\n",
    "    results = []\n",
    "    for node in similar_nodes:\n",
    "        results.append({\n",
    "            'text': node.node.text,\n",
    "            'metadata': node.node.metadata,\n",
    "            'similarity_score': node.score\n",
    "        })\n",
    "    \n",
    "    return results"
   ],
   "id": "b9c8bdf0b58c151f",
   "outputs": [],
   "execution_count": 158
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T09:27:13.773194Z",
     "start_time": "2025-08-28T09:27:13.759077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def majority_aggregation(value_list):\n",
    "    \"\"\"\n",
    "    Computes the majority vote of value_list. This makes the most sense as we are dealing with categorical data. \n",
    "    :param value_list: list of values\n",
    "    :return: float\n",
    "    \"\"\"\n",
    "    return Counter(value_list).most_common(1)[0][0]"
   ],
   "id": "57df4b9fca031076",
   "outputs": [],
   "execution_count": 160
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T09:27:14.358488Z",
     "start_time": "2025-08-28T09:27:14.339611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_from_similar_examples(similar_examples):\n",
    "    \"\"\"\n",
    "    Predict target value from similar examples\n",
    "    :param similar_examples: list of similar examples\n",
    "    :return: list of predictions\n",
    "    \"\"\"\n",
    "    if not similar_examples:\n",
    "        return None\n",
    "\n",
    "    target_values = [[ex['metadata']['bin_maj_label'] for ex in similar_examples],\n",
    "                     [ex['metadata']['bin_one_label'] for ex in similar_examples],\n",
    "                     [ex['metadata']['bin_all_label'] for ex in similar_examples],\n",
    "                     [ex['metadata']['multi_maj_label'] for ex in similar_examples],\n",
    "                     [ex['metadata']['disagree_bin_label'] for ex in similar_examples]]\n",
    "    \n",
    "    return [majority_aggregation(target_values) for target_values in target_values]\n",
    "        "
   ],
   "id": "aaf79c0895fb1acf",
   "outputs": [],
   "execution_count": 161
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T09:27:14.939513Z",
     "start_time": "2025-08-28T09:27:14.933664Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def data_to_dataframe(prediction):\n",
    "    \"\"\"\n",
    "    takes the output of run_rag_pipeline and turns it into a pandas dataframe with fitting columns for comparison\n",
    "    :param prediction: list of dictionaries of the form: {'query_text': , 'prediction':, 'num_similar_examples': 'similar_examples': } \n",
    "    :return: dataframe\n",
    "    \"\"\"\n",
    "    prediction = [{'text': p['query_text'], \n",
    "                'bin_maj_label': p['prediction'][0],\n",
    "                'bin_one_label': p['prediction'][1],\n",
    "                'bin_all_label': p['prediction'][2], \n",
    "                'multi_maj_label':p['prediction'][3],\n",
    "                'disagree_bin_label': p['prediction'][4],\n",
    "                'similar_text_1': p['similar_examples'][0]['text'].replace(\"\\n        Example Text:\", \"\"),\n",
    "                'similar_text_2': p['similar_examples'][1]['text'].replace(\"\\n        Example Text:\", \"\")} for p in prediction]\n",
    "    return pd.DataFrame(prediction, columns=prediction[0].keys())"
   ],
   "id": "5246177f2ab8dc18",
   "outputs": [],
   "execution_count": 162
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T09:27:15.504746Z",
     "start_time": "2025-08-28T09:27:15.490473Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_rag_pipeline(df, test_texts, model, top_k=5):\n",
    "    \"\"\"\n",
    "    Complete RAG pipeline using LlamaIndex\n",
    "    :param df: reference dataframe with text elements and labels\n",
    "    :param test_texts: list of test texts\n",
    "    :param model: str indicating which model to use for embeddings. If 'Bert', uses \"dbmdz/\n",
    "    :param top_k: int, number of similar examples\n",
    "    :return: dataframe  \n",
    "    \"\"\"\n",
    "    print(\"Step 1: Preparing training nodes...\")\n",
    "    training_nodes = prepare_training_nodes(df)\n",
    "    \n",
    "    print(\"Step 2: Creating/Reloading vector index...\")\n",
    "    index = create_reload_vector_index(training_nodes, model)\n",
    "    \n",
    "    print(\"Step 3: Making predictions...\")\n",
    "    predictions = []\n",
    "    \n",
    "    for test_text in test_texts:\n",
    "        similar_examples = retrieve_similar_examples(test_text, index, top_k)\n",
    "        prediction = predict_from_similar_examples(similar_examples)\n",
    "        predictions.append({\n",
    "            'query_text': test_text,\n",
    "            'prediction': prediction,\n",
    "            'num_similar_examples': len(similar_examples),\n",
    "            'similar_examples': similar_examples[:2] \n",
    "        })\n",
    "    #print(predictions)\n",
    "    \n",
    "    return data_to_dataframe(predictions)"
   ],
   "id": "63802a65f7d3bb31",
   "outputs": [],
   "execution_count": 163
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Let's see how well the indexing worked:",
   "id": "36c84f1e45677e7e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if run_this:\n",
    "    test_index_Bert = run_rag_pipeline(train_df,test_data[:10], \"Bert\")\n",
    "    test_index_e5 = run_rag_pipeline(train_df,test_data[:10], \"notBert\")"
   ],
   "id": "40025585aeff718b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T09:18:38.045190Z",
     "start_time": "2025-08-28T09:18:38.024296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for index, row in test_index_Bert.iterrows():\n",
    "    print('Text')\n",
    "    print(row['text'])\n",
    "    print('\\n Retrieved \"similar\" ones')\n",
    "    print(row['similar_text_1'])\n",
    "    print(row['similar_text_2'])"
   ],
   "id": "12e0cf7acaa0e096",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text\n",
      "Das ist ein richtig gutes Portrait von Greta!\n",
      "\n",
      " Retrieved \"similar\" ones\n",
      " was für ein foto!  ein dicker otto waalkes im dirndl und putin?\n",
      "        \n",
      " Und der Missbrauch von muslimischen Frauen ist wurscht? Was für ein menschenverachtendes Posting!\n",
      "        \n",
      "Text\n",
      "bei den dort üblichen kalaschnikows wärs eher eine zahl mit ein paar nullen mehr ...\n",
      "\n",
      " Retrieved \"similar\" ones\n",
      " Mit einer Frau an der Spitze würde es nur noch diese bequemen schlabbrigen Baumwollzelte im Angebot geben.  Obwohl ... Modell \"Lieschen Modermöse\" hat auch so seinen Reiz.\n",
      "        \n",
      " Man sollte schon noch unterscheiden zwischen Männern und sogenannten \"Fotzenknechten\". Die auf den  Bildern da oben sind zweites.  Echte Männer brauchen keine Pailettenhoodies, keine rosa Cowboyboots und auch keine 18Zoll Alufelgen von ihrem Audi im Ohrwaschellapperl.\n",
      "        \n",
      "Text\n",
      "Nein.Es war eine Single-Börse,  die den ganzen deutschsprachigen Raum umfasst- ich glaube Lovescout. Hat aber nur zu virtuellen Verbindungen geführt- eben weil die betreffenden Männer hunderte Kilometer von mir entfernt gewohnt haben.Und dann die Websingles mit 2 wirklichen Volltreffern.Und dort ist es mittlerweile ähnlich wie auf Facebook: Es treiben sich hauptsächlich ältere Semester dort herum.Ich hab auch die Geschichte mit psychologischem Persönlichkeitsprofil und Matching Points probiert- das war bei Lovescout gegen eine Gebühr möglich.Der Algorithmus hat mir nur Partnervorschläge gemacht, die mich in genau Null Kategorien angesprochen haben.\n",
      "\n",
      " Retrieved \"similar\" ones\n",
      " Ja seh ich auch so! Die Männer haben Angst bor mir weil ich in Indien war! Was für ein Bullshit...\n",
      "        \n",
      " Aha, das Fräulein Hübsch kennt sich also voll aus. Mit den Möglichkeiten in Asien.  Geh jetzt dein Kinderzimmer aufräumen und schau nicht so viel Raubersgschichtn im Fernsehen.\n",
      "        \n",
      "Text\n",
      "Weil die Welt heute ein Dorf ist.\n",
      "\n",
      " Retrieved \"similar\" ones\n",
      " Krude Propaganda? Es gibt ein paar Beispiele von Ländern dieser Erde. Nennen Sie mir eines mit hohem Wohlstand und wenig Arbeit.\n",
      "        \n",
      " Eh klar Frauen sind die armen Opfer.   So wird das nie was mit Emanzipation.\n",
      "        \n",
      "Text\n",
      "Wenn sich einer psychische Gewalt gefallen lässt, vor der man fliehen kann, da ja keine Bedrohung von Leib und Leben besteht wie bei körperlicher, liegt es im Ermessen des Mannes, ob er das will oder nicht. Ach wie liebe ich die Jammereien von euch Lappen, nur weil ihr zu feige und schwach seid, diese Partnerinnen zu verlassen, euch eine eigene Wohnung zu nehmen, ein eigenes Leben zu beginnen. Das kann eine Frau, die körperlich bedroht wird, nämlich NICHT machen, verstehst du?  Und ja, Männer begehen mehr Selbstmorde, weil sie gewaltbereiter (auch gegen sich selbst) sind und eben charakterlich schwächer, weniger aushalten (müssen) als Frauen. Da können Frauen nix dafür!\n",
      "\n",
      " Retrieved \"similar\" ones\n",
      " Warum soll ein Mann, der sich so eine Wohnung leisten kann, nicht so eine Frau haben? Soll er sich etwa eine Emanze antun, die Sprachpolizei spielt?\n",
      "        \n",
      " Genau, der physisch Stärkere und geistig Rohere soll ja nicht in seiner kulturell bedingten Unmutsäusserung behindert werden. Haben sie leicht Panik, dass sie nicht mehr gewalttätig werden können, ohne dass ihnen jemand mit einem Equalizer gegenübertritt?  Halt schon blöd, wenn sich Frauen wirksam wehren könnten.\n",
      "        \n",
      "Text\n",
      "Primtivlinge wie dich gibts glücklicherweise immer weniger, und die, die es gibt, wandern schön langsam in die Anstalten, in die sie gehören...\n",
      "\n",
      " Retrieved \"similar\" ones\n",
      " \"Ohne Frauen, die Kinder großziehen und ihren Männern \"den Rücken freihalten\",\"  Umgekehrt, meine Liebe. Umgekehrt. Ohne Männer, die diese Frauen (nota bene erwachsene Menschen!) erhalten! Könnte keine Wirtschaft bestehen.  Und gleichzeitig jammern, dass immer weniger kinder geboren werden. Das ist doch die Folge dieser dämlichen feministischen Männerhetze. Die Männer haben immer weniger Bock darauf.  Klar jammern die frauen dann, Kinder sind das einzige Druckmittel, das sie haben, um Männer weiterhin zu verpflichten, sie zu versorgen.\n",
      "        \n",
      " Irhendwie scheinen Sie in einer Parallelwelt zu leben.der. Man hört und liest niemals von Männer, die ab einem betimmten Alter verzweifelt wären, keine kinder zu haben. Das hört man nur von Frauen. \n",
      "        \n",
      "Text\n",
      "wenn Greta eine junge Frau sein soll, dann hat sie gefälligst ein bisserl busen zu haben, sonst ist sie ein kind, keine frau...\n",
      "\n",
      " Retrieved \"similar\" ones\n",
      " Warum soll ein Mann, der sich so eine Wohnung leisten kann, nicht so eine Frau haben? Soll er sich etwa eine Emanze antun, die Sprachpolizei spielt?\n",
      "        \n",
      " Wenn man eine gute Frau hat, teilt man sowieso mit ihr. Im Normalfall. Hat man aber mit einer bösen Hexe ein Kind gezeugt, ist jeder sicher froh wenn er möglichst bald weg von ihr ist und ihr auch nicht noch sein Geld in den Ar... blasen muss.  Per Gesetz zu teilen kommt für mich keinesfalls in Frage! Und dafür würde ich auch auf die Barrikaden steigen.\n",
      "        \n",
      "Text\n",
      "Habe ich nie behauptet, dass sie von einem Bett ins andere hüpfen .. Sie haben von 40 jährigen Ziegen gesprochen die sich ganz ohne blaue Pillen mit 50 jährigen vergnügen und aus der Ziegenrunde herzliche Grüße ausgerichtet ..Da Ziegen in der Regel ja nur um die 20 Jahre alt werden , kann es sich nur um einen Scherz gehandelt haben ..\n",
      "\n",
      " Retrieved \"similar\" ones\n",
      " und dann hacken sich die Damen gegenseitig um, wenn Eine glaubt mehr werden zu wollen als die Anderen.Und dann lassen Sie sich eher von einer dahergelaufenen Weh mit Zumpferl etwas sagen, als von einer anderen Frau.Pures Patriachat.....\n",
      "        \n",
      " Zumindest kann eine gewisse Trinkfestigkeit nicht schaden.Der Geschäftsführer der Hygiene Austria hat ja angeblich auch seinen Job bekommen, weil er einen russischen Oligarchen unter den Tisch getrunken hat. Da tun sich Frauen halt oft schwer.\n",
      "        \n",
      "Text\n",
      "Ich arbeite lieber mit Männern zusammen, weil die nicht so viel Förderung, Unterstützung und Verständnis brauchen, in schwierigen Zeiten jedenfalls. Kann Frau bitte einfach Informatik studieren ohne zu nerven? Ich habe das Gefühl, es mit Schwerbehinderten zu tun zu haben.\n",
      "\n",
      " Retrieved \"similar\" ones\n",
      " Und was glauben sie wie viel Zeit die Führungskräfte, die Väter sind für ihre Kinder haben?Ja, bei der Zeugung war der Vater zwangsläufig dabei, aber Führungskraft zu sein und dann noch 20-30h pro Woche für die Kinder zu haben geht sich für Frauen UND Männer kaum aus.\n",
      "        \n",
      " Ich kann aus eigener Erfahrung sprechen.Ich hab nichts gegen kluge, erfolgreiche Frauen.Mich interessiert die Karriere von Menschen einfach nicht. Entweder man kann eine schöne Zeit miteinander verbringen oder eben nicht.Das gleiche gilt für emanzipierte Frauen.Leiwand!Nur wenn eine Frau die ganze Zeit krampfhaft zeigen muss, dass sie „emanzipiert“ ist, ist das unheimlich anstrengend.Sich selbst einfach nicht zu ernst nehmen.\n",
      "        \n",
      "Text\n",
      "Stimmt - dort will man auch keine Frauen einstellen.\n",
      "\n",
      " Retrieved \"similar\" ones\n",
      " Na ja - diese blumigen Umschreibungen mögen die Standard-ZensiererInnen eben gar nicht.\n",
      "        \n",
      " Will doch schwer hoffen, denn das wäre seximus.\n",
      "        \n"
     ]
    }
   ],
   "execution_count": 148
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T09:18:49.262825Z",
     "start_time": "2025-08-28T09:18:49.252004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for index, row in test_index_e5.iterrows():\n",
    "    print('Text')\n",
    "    print(row['text'])\n",
    "    print('\\n Retrieved \"similar\" ones')\n",
    "    print(row['similar_text_1'])\n",
    "    print(row['similar_text_2'])"
   ],
   "id": "b5964ff5f05f4188",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text\n",
      "Das ist ein richtig gutes Portrait von Greta!\n",
      "\n",
      " Retrieved \"similar\" ones\n",
      " Also dass die Veilchen ja fast noch wärmer als die Grünen spielen können ist ja echt ein Kunststück!\n",
      "        \n",
      " Jungfrau Greta vom Ikealand Je mehr sie sich da hineinsteigert um so mehr CO2 sondert sie ab.\n",
      "        \n",
      "Text\n",
      "bei den dort üblichen kalaschnikows wärs eher eine zahl mit ein paar nullen mehr ...\n",
      "\n",
      " Retrieved \"similar\" ones\n",
      " In Österreich sind es eher die Neonazis mit Kalashnikovs die sich auf solchen .. Festen herumtreiben.\n",
      "        \n",
      " herzloser mittelfinga wär ein besserer nick\n",
      "        \n",
      "Text\n",
      "Nein.Es war eine Single-Börse,  die den ganzen deutschsprachigen Raum umfasst- ich glaube Lovescout. Hat aber nur zu virtuellen Verbindungen geführt- eben weil die betreffenden Männer hunderte Kilometer von mir entfernt gewohnt haben.Und dann die Websingles mit 2 wirklichen Volltreffern.Und dort ist es mittlerweile ähnlich wie auf Facebook: Es treiben sich hauptsächlich ältere Semester dort herum.Ich hab auch die Geschichte mit psychologischem Persönlichkeitsprofil und Matching Points probiert- das war bei Lovescout gegen eine Gebühr möglich.Der Algorithmus hat mir nur Partnervorschläge gemacht, die mich in genau Null Kategorien angesprochen haben.\n",
      "\n",
      " Retrieved \"similar\" ones\n",
      " Vielleicht liegt es auch einfach an den unterschiedlichen Vorstellungen von Männern und Frauen.Eine Freundin war eine zeitlang auf diversen Dating-Platformen unterwegs. Sie hatte es immer nur mit Männern zu tun die entweder was einmaliges (one-night stand) suchen, oder ein Spielzeug (was viel besser klingt, wenn ma erklärt ma is poly-amourös).Sie hat es dann irgendwann wieder gelassen.PS: ich weiß, größe des samples (N=1) ist statistisch nicht aussagekräftig.\n",
      "        \n",
      " Es ist keine “Schuldfrage” aber ein erfolgreicher, 48jähriger Mann sucht Frau von 25-50 von weniger erfolgreich bis MAX ähnlich erfolgreich und erfolgreiche 48jährige Frau sucht Man von 40-55 der MiNDESTENS so erfolgreich ist. Ob sie Zahlen genau stimmen ist egal, aber Konzept ist immer das gleiche: Männer suchen meist in grösserem Jahrgangspool UND haben - wenn sie selbst erfolgreich sind- WESENTLICH  mehr Auswahl innerhalb jedes Jahrgangs. Denke schon das man hier in der Praxis von “per se schwerer” reden kann. Ist es “Schuld dass sich 48jährige Frauen mit einem 25jährigen Partner seriös schwerer zu tun scheinen als umgekehrt?\n",
      "        \n",
      "Text\n",
      "Weil die Welt heute ein Dorf ist.\n",
      "\n",
      " Retrieved \"similar\" ones\n",
      " Ja ja, die 'gute alte Zeit' - das erinnert mich an meine Grundschule: da war's voellig normal, das Lehrer Watschen verteilt haben, auch der Dorfpfarrer, der gleichzeitig Religionslehrer war ... Und die Eltern der meisten Kinder haben nur gesagt, 'der Lehrer wird's schon wissen, des g'schieht da recht, Hundsbua'.  Was ich immer schlimm fand damals, war der Zahnarzt am Dorf, der war alt, grantig und herrisch, der nie was erklaert hat, und das, kobimiert mit der absoluten Hilflosigkeit als Kind im Behandlungsstuhl, war fuer mich der absolute Horror ... heute hab ich eine junge, freundliche, nette und sehr kompetente, die mir alles haarklein erklaert, und ich fuehl mich richtig gut aufgehoben und hab keine Angst mehr, hinzugehen.  Und ja, das wird bleiben, solange Menschen an Wunder glauben wollen, das ist das selbe wie mit Religionen. Bedenklich bei der Eso-Sache ist aber, welche Interessengruppen sich in der Szene tummeln.\n",
      "        \n",
      " Das WARUM würde mich auch interessieren. Meine These wäre, dass erstens schon die Evolutionsgeschichte eine Rolle spielt, zweitens dass man unser von unserer Kultur beeinflusstes Denken nicht außer Acht lassen kann. Bei unseren Brüdern :-) den Gorillas ist das so, dass trotz einem ganzen Harem von Frauen nur die Männer um den einzigen Führungsplatz in der ganzen Gruppe kämpfen :-) Ist ja nicht ganz auszuschließen, dass auch der Primatenart Homo sapiens noch ein Rest ähnlicher Gene wirkt. Aber genaueres weiß man nicht - oder will man nicht wissen :-)\n",
      "        \n",
      "Text\n",
      "Wenn sich einer psychische Gewalt gefallen lässt, vor der man fliehen kann, da ja keine Bedrohung von Leib und Leben besteht wie bei körperlicher, liegt es im Ermessen des Mannes, ob er das will oder nicht. Ach wie liebe ich die Jammereien von euch Lappen, nur weil ihr zu feige und schwach seid, diese Partnerinnen zu verlassen, euch eine eigene Wohnung zu nehmen, ein eigenes Leben zu beginnen. Das kann eine Frau, die körperlich bedroht wird, nämlich NICHT machen, verstehst du?  Und ja, Männer begehen mehr Selbstmorde, weil sie gewaltbereiter (auch gegen sich selbst) sind und eben charakterlich schwächer, weniger aushalten (müssen) als Frauen. Da können Frauen nix dafür!\n",
      "\n",
      " Retrieved \"similar\" ones\n",
      " Bursche weint - Lehrer interessiert es nicht, Note bleibt, Mitschüler lachen ihn aus!egen ist, aber ich weiß aus eigener Erfahrung auch, welche enormen psychischen Druck Frauen auf einen ausüben können, bloß, wenn da drüber jammerst, wirst als \"Weichei\" und \"Versager\" abgestempelt...hische Gewalt\" angewandt hat?\n",
      "        \n",
      " Eine Beziehung gehört beendet und/oder die Polizei eingeschalten,  wenn Misshandlungen in einer Beziehung stattfinden. Zigtausende Male aber geht es immer weiter mit den Misshandlungen, woran liegt das? Keine gute Erziehung? keine guten Eltern? wird so etwas nicht in der Schule thematisiert? Abhängigkeit wegen psychischer Krankheit (z.b. Borderline?) warum wird so etwas nicht breit thematisiert? Da müsste angesetzt werden. Bei den eigenen Schwächen. Nicht nur immer auf die bösen Männer zeigen (die eh böse sind), da bleibt man in der Opferrolle, bleibt schwach. #you too\n",
      "        \n",
      "Text\n",
      "Primtivlinge wie dich gibts glücklicherweise immer weniger, und die, die es gibt, wandern schön langsam in die Anstalten, in die sie gehören...\n",
      "\n",
      " Retrieved \"similar\" ones\n",
      " geh bitte...natürlich tun sie das...seit Ewigkeiten...Incel-Foren...Wikimannia, Männerrechtler, blabla...der Unterschied is nur, dass sie kein Leiberl gwinnen ausser bei jungen und Gleichgesinnten, weil \"echte\" Männer nicht so erbärmlich agieren würden.\n",
      "        \n",
      " Wenn ich mir die Kommentare der vielen Coronaverharmloser hier ansehe, seh ich mein Vorurteil bestätigt: Ihr seids Frühaufsteher, grantelnde Asketen...  So und ich geh nach dem Abpinkeln der Morgene***** wieder schlafen. Viel zu früh aufgewacht....\n",
      "        \n",
      "Text\n",
      "wenn Greta eine junge Frau sein soll, dann hat sie gefälligst ein bisserl busen zu haben, sonst ist sie ein kind, keine frau...\n",
      "\n",
      " Retrieved \"similar\" ones\n",
      " Ja, mir herzlich Wurscht, wie unbeliebt ich mich mit diesem Posting jetzt mache: Aber warum bekommt man mit knapp 20 oder jünger ein Kind? Warum bekommt eine blutjunge Dame, anstatt nach der Schule mal erwachsen zu werden, eine Ausbildung zu machen, arbeiten zu gehen, selbstständig zu werden, lieber mit irgendeinem Dahergelaufenen - und sorry, jemand, der sich, wie gemäß Artikel, gleich nach Bekanntgabe der Schwangerschaft verpisst, hat es nicht verdient, anders bezeichnet zu werden - ein Kind? Warum ist es unmenschlich, sowas zu fragen? Ich find's eher kurzsichtig und nicht gerade von Empathie zeugend, in solche Verhältnisse ein Kind zu setzen. Ich fände es richtig, wenn {USER} mehr unter die Arme gegriffen wird, aber die Frage nach längerfristiger Planung darf hoffentlich gestellt werden. Schwanger werden kann jede.\n",
      "        \n",
      " Zu dieser Entscheidung gratuliere ich Ihnen! Ihr anmaßendes, schulmeisterndes, überhebliches, von leeren Phrasen, sexistischen Vorurteilen und wirklich tief sitzender Frauenverachtung geleitetes Mansplaining, hätte sowieso nichts bewirkt. Ich bin eine Frau und sage ihnen: Mischen Sie sich nicht in Angelegenheiten, die Sie als Mann niemals betreffen können. Ich verlange von Männern auch nicht, dass sie sich beschneiden lassen, oder dass sie sich alle mit 18 einer Vasektomie unterziehen müssen, was der effizienteste und einfachste Schutz gegen ungewollte Schwangerschaften wäre.\n",
      "        \n",
      "Text\n",
      "Habe ich nie behauptet, dass sie von einem Bett ins andere hüpfen .. Sie haben von 40 jährigen Ziegen gesprochen die sich ganz ohne blaue Pillen mit 50 jährigen vergnügen und aus der Ziegenrunde herzliche Grüße ausgerichtet ..Da Ziegen in der Regel ja nur um die 20 Jahre alt werden , kann es sich nur um einen Scherz gehandelt haben ..\n",
      "\n",
      " Retrieved \"similar\" ones\n",
      " Im Gegensatz zu ihnen, werde ich nicht als Oma gesehen im Forum. Sie aber werden als Greis mit Tauben gesehen.Stalin und Weltkrieg. So spricht kein 50 jähriger! Und auch kein 60 jähriger. Der schmeisst sich in der Lederkluft auf sein Bike, mit einem blonden Hasen!\n",
      "        \n",
      " Mich würde interessieren, wie viele Deppen es gibt, die dann mit einer 50-jährigen frustrierten, alten Schachtel (außer die hatten vorher eine langjährige Beziehung) bewusst ein Kind produzieren, um dann Alimente zu zahlen.  Außer die sind 70+, dann ist ehe schon alles wurscht.\n",
      "        \n",
      "Text\n",
      "Ich arbeite lieber mit Männern zusammen, weil die nicht so viel Förderung, Unterstützung und Verständnis brauchen, in schwierigen Zeiten jedenfalls. Kann Frau bitte einfach Informatik studieren ohne zu nerven? Ich habe das Gefühl, es mit Schwerbehinderten zu tun zu haben.\n",
      "\n",
      " Retrieved \"similar\" ones\n",
      " Lasst Frauen halt arbeiten ihr Ignoranten, ihr nehmts ja doch immer lieber Männer als Kollegen. Grad in den so \"warum wollen Frauen nicht in technischen Berufen arbeiten\" Bereichen dominieren doch die  HTL Nerds, die eventuell grad mal studiert haben, aber sich noch immer im Bubenzimmer am sichersten fühlen.\n",
      "        \n",
      " Männer studieren lieber MINT-Fächer und Frauen dafür andere Sachen. Kann das nicht einfach so bleiben?\n",
      "        \n",
      "Text\n",
      "Stimmt - dort will man auch keine Frauen einstellen.\n",
      "\n",
      " Retrieved \"similar\" ones\n",
      " Schwachsinn zum Quadrat.Es ist nämlich eher umgekehrt: Viele Firmen suchen verzweifelt Frauen, weil sie sich nicht Sexismus vorwerfen lassen wollen, finden aber keine!Und wenn man dann doch mal eine findet, dann ist die weniger qualifiziert.Das funktioniert halt nur bei solchen Bullshit-Stellen wie als \"Gleichstellungsbeauftragte\".\n",
      "        \n",
      " auch Angebote dies zu erhöhen werden abgelehnt. Und wenn man mit denen spricht die hier arbeiten - die sagen ganz offen und ehrlich die ****** tun die sich einfach nicht an.sinnlose meetings, rigorose entscheidungen, stress, druck.... für bisschen mehr geld.Ich verstehe die damen vollkommens.\n",
      "        \n"
     ]
    }
   ],
   "execution_count": 149
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "With the e5 multilingual model, VectorStoreIndex seems to yield slightly better results, does this hold true for the predictions too?",
   "id": "71ed2cb8438cd7c1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Let's make some predictions and evaluate them!",
   "id": "d5a2834e3c8f839f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# First with the \"dbmdz/bert-base-german-uncased\" model",
   "id": "72c53fcd256a34c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if run_this:\n",
    "    predictions_Bert_5_df = run_rag_pipeline(train_df, test_data, \"Bert\", top_k=5)\n",
    "    predictions_Bert_10_df = run_rag_pipeline(train_df, test_data, \"Bert\", top_k=10)\n",
    "    predictions_Bert_20_df = run_rag_pipeline(train_df, test_data, \"Bert\", top_k=20)"
   ],
   "id": "fdbdf2b7056bf91e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T09:54:14.977587Z",
     "start_time": "2025-08-28T09:54:14.745178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('with k = 5')\n",
    "compute_f1(dev_df.iloc[:100], predictions_Bert_5_df)\n",
    "print('with k = 10')\n",
    "compute_f1(dev_df.iloc[:100], predictions_Bert_10_df) #performs best here and overall\n",
    "print('with k = 20')\n",
    "compute_f1(dev_df.iloc[:100], predictions_Bert_20_df)"
   ],
   "id": "27fba6aa26bc3b86",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with k = 5\n",
      "Dev set F1 score Bin Maj: 0.6504735195771761\n",
      "Dev set F1 score Bin One: 0.5367466666666667\n",
      "Dev set F1 score Bin All: 0.8348235294117647\n",
      "Dev set F1 score Multi Maj: 0.6423015873015874\n",
      "Dev set F1 score Disagree Bin: 0.632291543814129\n",
      "with k = 10\n",
      "Dev set F1 score Bin Maj: 0.7036011396011397\n",
      "Dev set F1 score Bin One: 0.5529845755581921\n",
      "Dev set F1 score Bin All: 0.8570327552986512\n",
      "Dev set F1 score Multi Maj: 0.7003333333333334\n",
      "Dev set F1 score Disagree Bin: 0.5868253968253968\n",
      "with k = 20\n",
      "Dev set F1 score Bin Maj: 0.7124080882352942\n",
      "Dev set F1 score Bin One: 0.5031111111111111\n",
      "Dev set F1 score Bin All: 0.8389743589743591\n",
      "Dev set F1 score Multi Maj: 0.6386732919254658\n",
      "Dev set F1 score Disagree Bin: 0.5875908099088692\n"
     ]
    }
   ],
   "execution_count": 178
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Now with the \"intfloat/multilingual-e5-large\" model",
   "id": "c0ef2d7f61acd407"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if run_this:\n",
    "    predictions_e5_5_df = run_rag_pipeline(train_df, test_data, \"notBert\", top_k=5)\n",
    "    predictions_e5_10_df = run_rag_pipeline(train_df, test_data, \"notBert\", top_k=10)\n",
    "    predictions_e5_20_df = run_rag_pipeline(train_df, test_data, \"notBert\", top_k=20)"
   ],
   "id": "6e889def7d441153",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-28T09:59:56.140527Z",
     "start_time": "2025-08-28T09:59:56.078450Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('with k = 5')\n",
    "compute_f1(dev_df.iloc[:100], predictions_e5_5_df) #performs best here\n",
    "print('with k = 10')\n",
    "compute_f1(dev_df.iloc[:100], predictions_e5_10_df)\n",
    "print('with k = 20')\n",
    "compute_f1(dev_df.iloc[:100], predictions_e5_20_df)"
   ],
   "id": "55e6adae1d19bcb8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "with k = 5\n",
      "Dev set F1 score Bin Maj: 0.7029249011857708\n",
      "Dev set F1 score Bin One: 0.5956626506024096\n",
      "Dev set F1 score Bin All: 0.8341621621621621\n",
      "Dev set F1 score Multi Maj: 0.6412717536813922\n",
      "Dev set F1 score Disagree Bin: 0.5785291425083918\n",
      "with k = 10\n",
      "Dev set F1 score Bin Maj: 0.7135690396559962\n",
      "Dev set F1 score Bin One: 0.5674819541793075\n",
      "Dev set F1 score Bin All: 0.8188235294117647\n",
      "Dev set F1 score Multi Maj: 0.6366279069767442\n",
      "Dev set F1 score Disagree Bin: 0.5483636363636363\n",
      "with k = 20\n",
      "Dev set F1 score Bin Maj: 0.6420833333333335\n",
      "Dev set F1 score Bin One: 0.57984\n",
      "Dev set F1 score Bin All: 0.8238297872340425\n",
      "Dev set F1 score Multi Maj: 0.6428571428571428\n",
      "Dev set F1 score Disagree Bin: 0.6078817733990148\n"
     ]
    }
   ],
   "execution_count": 180
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Conclusion",
   "id": "fa02d0112e6faee6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Pro: No issues with reproducibility here\n",
    "Contra: Results are worse compared to the results from \"comparisonAPI.ipynb\"."
   ],
   "id": "559991cce98e9e65"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
