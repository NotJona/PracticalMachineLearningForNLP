{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Setup ",
   "id": "63182982ad0e4f0c"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": "!pip install transformers[torch] datasets scikit-learn pandas numpy",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:48:33.006386Z",
     "start_time": "2025-08-23T08:48:32.941439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from collections import Counter\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ],
   "id": "535a82afb6a7a671",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "from functions import load_jsonl",
   "id": "6e418d6d3f021601"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Global Variables\n",
   "id": "ddd567ceb568edc9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Data\n",
    "train_file_path = Path('data_germeval/train.jsonl')\n",
    "dev_file_path = Path('data_germeval/development.jsonl')\n",
    "test_file_path = Path('data_germeval/test.jsonl')\n",
    "\n",
    "# Model \n",
    "model_name = 'google-bert/bert-base-german-cased'\n",
    "\n",
    "# Log directories\n",
    "output_dir_bin_maj = Path('./logs/run_final_bin_maj/')\n",
    "output_dir_bin_one = Path('./logs/run_final_bin_one/')\n",
    "output_dir_bin_all = Path('./logs/run_final_bin_all/')\n",
    "output_dir_multi_maj = Path('./logs/run_final_multi_maj/')\n",
    "output_dir_disagree_bin = Path('./logs/run_final_disagree_bin/')\n",
    "\n",
    "# Model directories\n",
    "model_path_bin_maj = Path(\"models/bin_maj_model\")\n",
    "model_path_bin_one = Path(\"models/bin_one_model\")\n",
    "model_path_bin_all = Path(\"models/bin_all_model\")\n",
    "model_path_multi_maj = Path(\"models/multi_maj_model\")\n",
    "model_path_disagree_bin = Path(\"models/disagree_bin_model\")\n",
    "\n",
    "#do we want to do the training?\n",
    "run_this = False"
   ],
   "id": "2a42732f89bdfa9c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Let us load our data",
   "id": "58ed7243d913dcf9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:08:57.266436Z",
     "start_time": "2025-08-23T08:08:57.233566Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = load_jsonl(train_file_path)\n",
    "dev_data = load_jsonl(dev_file_path)\n",
    "test_data = load_jsonl(test_file_path)"
   ],
   "id": "ed58534c3d916130",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Let us define the functions that compute the different labels for the germeval task",
   "id": "cde1143fdad68f12"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Version \"bin_maj\"",
   "id": "4d251101693bdfa5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:08:57.789191Z",
     "start_time": "2025-08-23T08:08:57.784685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def assign_bin_maj(item, is_test=False):\n",
    "    \"\"\"\n",
    "    takes a tweet and its annotations (if available) and computes 1 if a majority of annotators assigned a label other than 0-Kein, predicts 0 if a majority assigned 0-Kein. If there was no majority, either label is considered correct for evaluation.\n",
    "    :param item: dictionary of the form {'id': , 'text': , 'annotators': }\n",
    "    :param is_test: if False annotations are available. If True not\n",
    "    :return: dictionary of the form {'id': , 'text': , 'label': }\n",
    "    \"\"\"\n",
    "    text = item['text']\n",
    "    text = text.replace('\\n', ' ')\n",
    "    if not is_test:\n",
    "        labels = [ann['label'] for ann in item['annotations']]\n",
    "        label_counts = Counter(labels)\n",
    "        majority_label, majority_count = label_counts.most_common(1)[0]\n",
    "        bin_maj_label = 1 if majority_label != '0-Kein' else 0\n",
    "    else:\n",
    "        bin_maj_label = None\n",
    "    return {'id': item['id'], 'text': text, 'label': bin_maj_label}\n",
    "    "
   ],
   "id": "bfc6ab773fa0752d",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Version \"bin_one\"",
   "id": "1e2d29637f5a2c72"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:08:57.828877Z",
     "start_time": "2025-08-23T08:08:57.823355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def assign_bin_one(item, is_test=False):\n",
    "    \"\"\"\n",
    "    takes a tweet and its annotations (if available) and computes 1 if at least one annotator assigned a label other than 0-Kein, 0 otherwise.\n",
    "    :param item: dictionary of the form {'id': , 'text': , 'annotators': }\n",
    "    :param is_test: if False annotations are available. If True not\n",
    "    :return: dictionary of the form {'id': , 'text': , 'label': }\n",
    "    \"\"\"\n",
    "    text = item['text']\n",
    "    text = text.replace('\\n', ' ')\n",
    "    if not is_test:\n",
    "        bin_one_label = 1 if any(ann['label'] != '0-Kein' for ann in item['annotations']) else 0\n",
    "    else:\n",
    "        bin_one_label = None\n",
    "    return {'id': item['id'], 'text': text, 'label': bin_one_label}"
   ],
   "id": "82fbad55bd5c0691",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Version \"bin_all\"",
   "id": "27b5981245ce690c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:08:57.845957Z",
     "start_time": "2025-08-23T08:08:57.840909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def assign_bin_all(item, is_test=False):\n",
    "    \"\"\"\n",
    "    takes a tweet and its annotations (if available) and computes 1 if all annotators assigned labels other than 0-Kein, 0 otherwise.\n",
    "    :param item: dictionary of the form {'id': , 'text': , 'annotators': }\n",
    "    :param is_test: if False annotations are available. If True not\n",
    "    :return: dictionary of the form {'id': , 'text': , 'label': }\n",
    "    \"\"\"\n",
    "    text = item['text']\n",
    "    text = text.replace('\\n', ' ')\n",
    "    if not is_test:\n",
    "        bin_all_label = 1 if all(ann['label'] != '0-Kein' for ann in item['annotations']) else 0\n",
    "    else:\n",
    "        bin_all_label = None\n",
    "    return {'id': item['id'], 'text': text, 'label': bin_all_label}"
   ],
   "id": "1bded10a91c6926c",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Version \"multi_maj\"",
   "id": "136a784630eba323"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:08:57.858488Z",
     "start_time": "2025-08-23T08:08:57.852983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def assign_multi_maj(item, is_test=False):\n",
    "    \"\"\"\n",
    "    takes a tweet and its annotations (if available) and predicts the majority label if there is one, if there is no majority label, any of the labels assigned is counted as a correct prediction for evaluation.\n",
    "    :param item: dictionary of the form {'id': , 'text': , 'annotators': }\n",
    "    :param is_test: if False annotations are available. If True not\n",
    "    :return: dictionary of the form {'id': , 'text': , 'label': }\n",
    "    \"\"\"\n",
    "    text = item['text']\n",
    "    text = text.replace('\\n', ' ')\n",
    "    if not is_test:\n",
    "        labels = [ann['label'] for ann in item['annotations']]\n",
    "        label_counts = Counter(labels)\n",
    "        majority_label, majority_count = label_counts.most_common(1)[0]\n",
    "        multi_maj_label = majority_label if majority_count > len(labels) / 2 else labels[0]\n",
    "        multi_maj_label = int(multi_maj_label.split('-')[0])\n",
    "    else:\n",
    "        multi_maj_label = None\n",
    "    return {'id': item['id'], 'text': text, 'label': multi_maj_label}"
   ],
   "id": "235981f629474fab",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Version \"disagree bin\"",
   "id": "e22062f52f37b9f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:08:57.870536Z",
     "start_time": "2025-08-23T08:08:57.865745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def assign_disagree_bin(item, is_test=False):\n",
    "    \"\"\"\n",
    "    takes a tweet and its annotations (if available) and predicts 1 if there is a disagreement between annotators on 0-Kein versus all other labels and 0 otherwise.\n",
    "    :param item: dictionary of the form {'id': , 'text': , 'annotators': }\n",
    "    :param is_test: if False annotations are available. If True not\n",
    "    :return: dictionary of the form {'id': , 'text': , 'label': }\n",
    "    \"\"\"\n",
    "    text = item['text']\n",
    "    text = text.replace('\\n', ' ')\n",
    "    if not is_test:\n",
    "        labels = [ann['label'] for ann in item['annotations']]\n",
    "        unique_labels = set(labels)\n",
    "        disagree_bin_label = 1 if '0-Kein' in unique_labels and len(unique_labels) > 1 else 0\n",
    "    else:\n",
    "        disagree_bin_label = None\n",
    "    return {'id': item['id'], 'text': text, 'label': disagree_bin_label}"
   ],
   "id": "df98e947fb06d5b0",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Let us not define the function, that transforms our data into the suitable objects, i.e., huggingface datasets",
   "id": "65b5b5be01741c1b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:08:57.883352Z",
     "start_time": "2025-08-23T08:08:57.878307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def transform(func, data, is_test=False):\n",
    "    \"\"\"\n",
    "    Computes a particular label for a whole set of data\n",
    "    :param func: one of the five functions defined above\n",
    "    :param data: list of dictionaries\n",
    "    :param is_test: if False annotations are available. If True not\n",
    "    :return: huggingface dataset  \n",
    "    \"\"\"\n",
    "    transformed_data = []\n",
    "    for item in data:\n",
    "        transformed_data.append(func(item, is_test))\n",
    "    return Dataset.from_list(transformed_data)"
   ],
   "id": "d9dd72223c670fbf",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Now we have to load the tokenizer and then we can train our models",
   "id": "3ee55f775f12679d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:08:58.724371Z",
     "start_time": "2025-08-23T08:08:57.891469Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer = BertTokenizer.from_pretrained(model_name)",
   "id": "2e6cf8ad29759a49",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:08:58.741016Z",
     "start_time": "2025-08-23T08:08:58.737080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize_seqs(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,   # or padding=True\n",
    "        max_length=512\n",
    "    )"
   ],
   "id": "2afdd00f0c772e87",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "do we want to train?",
   "id": "1eb973e5e1a0390d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Preparing for training",
   "id": "759d13b6e75c3956"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's define our metrics for evaluation:",
   "id": "40ba68746d9ac6c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:08:58.765046Z",
     "start_time": "2025-08-23T08:08:58.761978Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    preds = eval_preds.predictions.argmax(-1)\n",
    "    lbls = eval_preds.label_ids\n",
    "    f1 = f1_score(lbls, preds, average='weighted')\n",
    "    return {'f1': f1}"
   ],
   "id": "aba704c828212599",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Let's set up our bin_maj data and model:",
   "id": "bf80ded14d8a8be6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:26:10.515797Z",
     "start_time": "2025-08-23T08:26:06.697297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenized_train_bin_maj = transform(assign_bin_maj, train_data).map(tokenize_seqs, batched=True)\n",
    "tokenized_dev_bin_maj = transform(assign_bin_maj, dev_data).map(tokenize_seqs, batched=True)\n",
    "tokenized_test_bin_maj = transform(assign_bin_maj, test_data, is_test= True).map(tokenize_seqs, batched=True)"
   ],
   "id": "fd3d1aa36cf8fd68",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3588/3588 [00:02<00:00, 1330.33 examples/s]\n",
      "Map: 100%|██████████| 449/449 [00:00<00:00, 2005.72 examples/s]\n",
      "Map: 100%|██████████| 449/449 [00:00<00:00, 1952.15 examples/s]\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:09:03.969868Z",
     "start_time": "2025-08-23T08:09:03.056051Z"
    }
   },
   "cell_type": "code",
   "source": "model_bin_maj = BertForSequenceClassification.from_pretrained(model_name, num_labels = 2)",
   "id": "29b43fd85533d3d9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:09:04.025296Z",
     "start_time": "2025-08-23T08:09:04.007121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_args_bin_maj= TrainingArguments(\n",
    "    output_dir=output_dir_bin_maj,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=1e-5,\n",
    "    weight_decay=5e-3,\n",
    "    num_train_epochs=3,\n",
    "    logging_steps= 30,\n",
    "    save_strategy='epoch',\n",
    "    eval_strategy='epoch',\n",
    "    save_total_limit=1,\n",
    "    seed=42,\n",
    "    data_seed=42,\n",
    "    fp16=True,\n",
    "    dataloader_num_workers=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",  \n",
    "    dataloader_pin_memory=False\n",
    ")"
   ],
   "id": "db8c29a93ce5b107",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:09:04.070356Z",
     "start_time": "2025-08-23T08:09:04.041063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer_bin_maj = Trainer(\n",
    "    model=model_bin_maj,\n",
    "    args=training_args_bin_maj,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=tokenized_train_bin_maj,\n",
    "    eval_dataset=tokenized_dev_bin_maj,\n",
    "    processing_class = tokenizer\n",
    ")"
   ],
   "id": "985fa06c9dcd9661",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:09:04.088522Z",
     "start_time": "2025-08-23T08:09:04.083017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if run_this:\n",
    "    trainer_bin_maj.train()\n",
    "    trainer_bin_maj.save_model(model_path_bin_maj)"
   ],
   "id": "debc063a9c5bf6f4",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Let's set up our bin_one data and model:",
   "id": "4795eb1918748c04"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:26:15.649957Z",
     "start_time": "2025-08-23T08:26:11.528986Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenized_train_bin_one = transform(assign_bin_one, train_data).map(tokenize_seqs, batched=True)\n",
    "tokenized_dev_bin_one = transform(assign_bin_one, dev_data).map(tokenize_seqs, batched=True)\n",
    "tokenized_test_bin_one = transform(assign_bin_one, test_data, is_test=True).map(tokenize_seqs, batched=True)"
   ],
   "id": "f37034e8a77193a5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3588/3588 [00:02<00:00, 1216.63 examples/s]\n",
      "Map: 100%|██████████| 449/449 [00:00<00:00, 1796.64 examples/s]\n",
      "Map: 100%|██████████| 449/449 [00:00<00:00, 1282.16 examples/s]\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:09:08.150861Z",
     "start_time": "2025-08-23T08:09:07.677501Z"
    }
   },
   "cell_type": "code",
   "source": "model_bin_one = BertForSequenceClassification.from_pretrained(model_name, num_labels = 2)",
   "id": "ed6ae1b2dc8eee36",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:09:08.178482Z",
     "start_time": "2025-08-23T08:09:08.169326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_args_bin_one= TrainingArguments(\n",
    "    output_dir=output_dir_bin_one,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=1e-5,\n",
    "    weight_decay=5e-3,\n",
    "    num_train_epochs=3,\n",
    "    logging_steps= 30,\n",
    "    save_strategy='epoch',\n",
    "    eval_strategy='epoch',\n",
    "    save_total_limit=1,\n",
    "    seed=42,\n",
    "    data_seed=42,\n",
    "    fp16=True,\n",
    "    dataloader_num_workers=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",  \n",
    "    dataloader_pin_memory=False\n",
    ")"
   ],
   "id": "6de3b2ab593ef908",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:09:08.209588Z",
     "start_time": "2025-08-23T08:09:08.196957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer_bin_one = Trainer(\n",
    "    model=model_bin_one,\n",
    "    args=training_args_bin_one,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=tokenized_train_bin_one,\n",
    "    eval_dataset=tokenized_dev_bin_one,\n",
    "    processing_class = tokenizer\n",
    ")"
   ],
   "id": "fb203c4c4b999cf9",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:09:08.223857Z",
     "start_time": "2025-08-23T08:09:08.219561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if run_this:\n",
    "    trainer_bin_one.train()\n",
    "    trainer_bin_one.save_model(model_path_bin_one)"
   ],
   "id": "d6354cb315fa3b54",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Let's set up our bin_all data and model:",
   "id": "fdb2755c95f8ec7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:09:12.123253Z",
     "start_time": "2025-08-23T08:09:08.242028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenized_train_bin_all = transform(assign_bin_all, train_data).map(tokenize_seqs, batched=True)\n",
    "tokenized_dev_bin_all = transform(assign_bin_all, dev_data).map(tokenize_seqs, batched=True)\n",
    "tokenized_test_bin_all = transform(assign_bin_all, test_data, is_test=True).map(tokenize_seqs, batched=True)"
   ],
   "id": "e7b8b40c6ebc042d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3588/3588 [00:02<00:00, 1387.87 examples/s]\n",
      "Map: 100%|██████████| 449/449 [00:00<00:00, 1191.41 examples/s]\n",
      "Map: 100%|██████████| 449/449 [00:00<00:00, 1678.94 examples/s]\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:09:12.674474Z",
     "start_time": "2025-08-23T08:09:12.142611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_bin_all = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "training_args_bin_all = TrainingArguments(\n",
    "    output_dir=output_dir_bin_all,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=1e-5,\n",
    "    weight_decay=5e-3,\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=30,\n",
    "    save_strategy='epoch',\n",
    "    eval_strategy='epoch',\n",
    "    save_total_limit=1,\n",
    "    seed=42,\n",
    "    data_seed=42,\n",
    "    fp16=True,\n",
    "    dataloader_num_workers=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    dataloader_pin_memory=False\n",
    ")"
   ],
   "id": "fccfc02b4735bb03",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:09:12.775035Z",
     "start_time": "2025-08-23T08:09:12.727630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer_bin_all = Trainer(\n",
    "    model=model_bin_all,\n",
    "    args=training_args_bin_all,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=tokenized_train_bin_all,\n",
    "    eval_dataset=tokenized_dev_bin_all,\n",
    "    processing_class=tokenizer\n",
    ")"
   ],
   "id": "99ffc1fec4efed5",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:09:12.796718Z",
     "start_time": "2025-08-23T08:09:12.792727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if run_this:\n",
    "    trainer_bin_all.train()\n",
    "    trainer_bin_all.save_model(model_path_bin_all)"
   ],
   "id": "97ee4475e7c57031",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Let's set up our multi_maj data and model:",
   "id": "92de757d5b28c0ba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:09:15.899682Z",
     "start_time": "2025-08-23T08:09:12.817111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenized_train_multi_maj = transform(assign_multi_maj, train_data).map(tokenize_seqs, batched=True)\n",
    "tokenized_dev_multi_maj = transform(assign_multi_maj, dev_data).map(tokenize_seqs, batched=True)\n",
    "tokenized_test_multi_maj = transform(assign_multi_maj, test_data, is_test=True).map(tokenize_seqs, batched=True)"
   ],
   "id": "7f6c9bcc966d8a3a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3588/3588 [00:01<00:00, 1947.05 examples/s]\n",
      "Map: 100%|██████████| 449/449 [00:00<00:00, 1389.22 examples/s]\n",
      "Map: 100%|██████████| 449/449 [00:00<00:00, 1279.60 examples/s]\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:09:16.531632Z",
     "start_time": "2025-08-23T08:09:15.986682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_multi_maj = BertForSequenceClassification.from_pretrained(model_name, num_labels=5)\n",
    "training_args_multi_maj = TrainingArguments(\n",
    "    output_dir=output_dir_multi_maj,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=1e-5,\n",
    "    weight_decay=5e-3,\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=30,\n",
    "    save_strategy='epoch',\n",
    "    eval_strategy='epoch',\n",
    "    save_total_limit=1,\n",
    "    seed=42,\n",
    "    data_seed=42,\n",
    "    fp16=True,\n",
    "    dataloader_num_workers=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    dataloader_pin_memory=False\n",
    ")"
   ],
   "id": "83fdc6d2b2218faf",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:09:16.678844Z",
     "start_time": "2025-08-23T08:09:16.635720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer_multi_maj = Trainer(\n",
    "    model=model_multi_maj,\n",
    "    args=training_args_multi_maj,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=tokenized_train_multi_maj,\n",
    "    eval_dataset=tokenized_dev_multi_maj,\n",
    "    processing_class=tokenizer\n",
    ")"
   ],
   "id": "eae1e40e0ca9d933",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:09:16.753904Z",
     "start_time": "2025-08-23T08:09:16.746768Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if run_this:\n",
    "    trainer_multi_maj.train()\n",
    "    trainer_multi_maj.save_model(model_path_multi_maj)"
   ],
   "id": "d39fc4fe67edc5ee",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Let's set up our disagree_bin data and model:",
   "id": "902bfc62ff88937d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:09:20.239347Z",
     "start_time": "2025-08-23T08:09:16.802538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenized_train_disagree_bin = transform(assign_disagree_bin, train_data).map(tokenize_seqs, batched=True)\n",
    "tokenized_dev_disagree_bin = transform(assign_disagree_bin, dev_data).map(tokenize_seqs, batched=True)\n",
    "tokenized_test_disagree_bin = transform(assign_disagree_bin, test_data, is_test=True).map(tokenize_seqs, batched=True)"
   ],
   "id": "3f8f3ba6f65ca124",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3588/3588 [00:02<00:00, 1757.55 examples/s]\n",
      "Map: 100%|██████████| 449/449 [00:00<00:00, 1156.88 examples/s]\n",
      "Map: 100%|██████████| 449/449 [00:00<00:00, 1840.66 examples/s]\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:09:20.686669Z",
     "start_time": "2025-08-23T08:09:20.257640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_disagree_bin = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "training_args_disagree_bin = TrainingArguments(\n",
    "    output_dir=output_dir_disagree_bin,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    gradient_accumulation_steps=2,\n",
    "    learning_rate=1e-5,\n",
    "    weight_decay=5e-3,\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=30,\n",
    "    save_strategy='epoch',\n",
    "    eval_strategy='epoch',\n",
    "    save_total_limit=1,\n",
    "    seed=42,\n",
    "    data_seed=42,\n",
    "    fp16=True,\n",
    "    dataloader_num_workers=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    dataloader_pin_memory=False\n",
    ")"
   ],
   "id": "3183fcad45b4662",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:09:20.811552Z",
     "start_time": "2025-08-23T08:09:20.789493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trainer_disagree_bin = Trainer(\n",
    "    model=model_disagree_bin,\n",
    "    args=training_args_disagree_bin,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=tokenized_train_disagree_bin,\n",
    "    eval_dataset=tokenized_dev_disagree_bin,\n",
    "    processing_class=tokenizer\n",
    ")"
   ],
   "id": "283c6dfc712f5d1",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:09:20.832490Z",
     "start_time": "2025-08-23T08:09:20.825788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if run_this:\n",
    "    trainer_disagree_bin.train()\n",
    "    trainer_disagree_bin.save_model(model_path_disagree_bin)"
   ],
   "id": "214273b878dca8d8",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Let us make some predictions!",
   "id": "f9f40e267b81e286"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# First we have to load the different models",
   "id": "1c55a969ff81507e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:09:21.299428Z",
     "start_time": "2025-08-23T08:09:20.850042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_bin_maj = BertForSequenceClassification.from_pretrained(model_path_bin_maj)\n",
    "\n",
    "trainer_bin_maj = Trainer(\n",
    "    model=model_bin_maj,\n",
    "    args=training_args_bin_maj,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=tokenized_train_bin_maj,\n",
    "    eval_dataset=tokenized_dev_bin_maj,\n",
    "    processing_class = tokenizer\n",
    ")\n",
    "\n",
    "model_bin_all = BertForSequenceClassification.from_pretrained(model_path_bin_all)\n",
    "\n",
    "trainer_bin_all = Trainer(\n",
    "    model=model_bin_all,\n",
    "    args=training_args_bin_all,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=tokenized_train_bin_all,\n",
    "    eval_dataset=tokenized_dev_bin_all,\n",
    "    processing_class = tokenizer\n",
    ")\n",
    "\n",
    "model_bin_one = BertForSequenceClassification.from_pretrained(model_path_bin_one)\n",
    "\n",
    "trainer_bin_one = Trainer(\n",
    "    model=model_bin_one,\n",
    "    args=training_args_bin_one,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=tokenized_train_bin_one,\n",
    "    eval_dataset=tokenized_dev_bin_one,\n",
    "    processing_class = tokenizer\n",
    ")\n",
    "\n",
    "model_multi_maj = BertForSequenceClassification.from_pretrained(model_path_multi_maj)\n",
    "\n",
    "trainer_multi_maj = Trainer(\n",
    "    model=model_multi_maj,\n",
    "    args=training_args_multi_maj,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=tokenized_train_multi_maj,\n",
    "    eval_dataset=tokenized_dev_multi_maj,\n",
    "    processing_class = tokenizer\n",
    ")\n",
    "\n",
    "model_disagree_bin = BertForSequenceClassification.from_pretrained(model_path_disagree_bin)\n",
    "\n",
    "trainer_disagree_bin = Trainer(\n",
    "    model=model_disagree_bin,\n",
    "    args=training_args_disagree_bin,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=tokenized_train_disagree_bin,\n",
    "    eval_dataset=tokenized_dev_disagree_bin,\n",
    "    processing_class = tokenizer\n",
    ")"
   ],
   "id": "5bde843ee1221104",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Now we can make some predictions",
   "id": "ebf7177e9e8e18e4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:09:21.316773Z",
     "start_time": "2025-08-23T08:09:21.312266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def determine_label(prediction):\n",
    "  labels = []\n",
    "  for score in prediction[0]:\n",
    "    labels.append(np.where(score == max(score))[0][0])\n",
    "  return labels"
   ],
   "id": "1976d563acde0240",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# First let's check the dev sets, since here we have reference data (though there is actually no need to do this, as we already know the outcome - but good to see it works)",
   "id": "33ae067b50b9f8cb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:18:27.699848Z",
     "start_time": "2025-08-23T08:09:21.332804Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dev_predictions_bin_maj = trainer_bin_maj.predict(test_dataset=tokenized_dev_bin_maj)\n",
    "dev_predictions_bin_one = trainer_bin_one.predict(test_dataset=tokenized_dev_bin_one)\n",
    "dev_predictions_bin_all = trainer_bin_all.predict(test_dataset=tokenized_dev_bin_all)\n",
    "dev_predictions_multi_maj = trainer_multi_maj.predict(test_dataset=tokenized_dev_multi_maj)\n",
    "dev_predictions_disagree_bin = trainer_disagree_bin.predict(test_dataset=tokenized_dev_disagree_bin)"
   ],
   "id": "c3bdf79fbe5a3878",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:18:27.840228Z",
     "start_time": "2025-08-23T08:18:27.826688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Dev set F1 score Bin Maj: {dev_predictions_bin_maj.metrics['test_f1']:.4f}\")\n",
    "print(f\"Dev set F1 score Bin One: {dev_predictions_bin_one.metrics['test_f1']:.4f}\")\n",
    "print(f\"Dev set F1 score Bin All: {dev_predictions_bin_all.metrics['test_f1']:.4f}\")\n",
    "print(f\"Dev set F1 score Multi Maj: {dev_predictions_multi_maj.metrics['test_f1']:.4f}\")\n",
    "print(f\"Dev set F1 score Disagree Bin: {dev_predictions_disagree_bin.metrics['test_f1']:.4f}\")"
   ],
   "id": "a10def0638645e55",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev set F1 score Bin Maj: 0.7610\n",
      "Dev set F1 score Bin One: 0.7572\n",
      "Dev set F1 score Bin All: 0.8308\n",
      "Dev set F1 score Multi Maj: 0.6532\n",
      "Dev set F1 score Disagree Bin: 0.6741\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Let's make predictions for the testset now. ",
   "id": "d974ba7411dcc91d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:25:56.732076Z",
     "start_time": "2025-08-23T08:18:27.898595Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenized_test_bin_maj = tokenized_test_bin_maj.remove_columns(['label'])\n",
    "test_predictions_bin_maj = trainer_bin_maj.predict(test_dataset=tokenized_test_bin_maj)\n",
    "tokenized_test_bin_one = tokenized_test_bin_one.remove_columns(['label'])\n",
    "test_predictions_bin_one = trainer_bin_one.predict(test_dataset=tokenized_test_bin_one)\n",
    "tokenized_test_bin_all = tokenized_test_bin_all.remove_columns(['label'])\n",
    "test_predictions_bin_all = trainer_bin_all.predict(test_dataset=tokenized_test_bin_all)\n",
    "tokenized_test_multi_maj = tokenized_test_multi_maj.remove_columns(['label'])\n",
    "test_predictions_multi_maj = trainer_multi_maj.predict(test_dataset=tokenized_test_multi_maj)\n",
    "tokenized_test_disagree_bin = tokenized_test_disagree_bin.remove_columns(['label'])\n",
    "test_predictions_disagree_bin = trainer_disagree_bin.predict(test_dataset=tokenized_test_disagree_bin)"
   ],
   "id": "9654780d8ab296f2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:25:56.882685Z",
     "start_time": "2025-08-23T08:25:56.873584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def determine_label(prediction):\n",
    "  labels = []\n",
    "  for score in prediction[0]:\n",
    "    labels.append(np.where(score == max(score))[0][0])\n",
    "  return labels"
   ],
   "id": "5869d5f3f95bb48b",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:25:56.963988Z",
     "start_time": "2025-08-23T08:25:56.945376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predicted_bin_maj_labels_test_set = determine_label(test_predictions_bin_maj)\n",
    "predicted_bin_one_labels_test_set = determine_label(test_predictions_bin_one)\n",
    "predicted_bin_all_labels_test_set = determine_label(test_predictions_bin_all)\n",
    "predicted_multi_maj_labels_test_set = determine_label(test_predictions_multi_maj)\n",
    "predicted_disagree_bin_labels_test_set = determine_label(test_predictions_disagree_bin)"
   ],
   "id": "736112b95f577573",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:25:57.046238Z",
     "start_time": "2025-08-23T08:25:57.039318Z"
    }
   },
   "cell_type": "code",
   "source": "predicted_multi_maj_labels_test_set_with_label =[['0-Kein', '1-Gering', '2-Vorhanden', '3-Stark', '4-Extrem'][i] for i in predicted_multi_maj_labels_test_set]",
   "id": "3febdbe69d5ac322",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-23T08:25:57.177941Z",
     "start_time": "2025-08-23T08:25:57.120428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import csv\n",
    "\n",
    "id_test = tokenized_test_bin_maj['id']\n",
    "\n",
    "rows = zip(id_test,\n",
    "           predicted_bin_maj_labels_test_set,\n",
    "           predicted_bin_one_labels_test_set,\n",
    "           predicted_bin_all_labels_test_set,\n",
    "           predicted_multi_maj_labels_test_set_with_label,\n",
    "           predicted_disagree_bin_labels_test_set)\n",
    "\n",
    "header = [\"id\", \"bin_maj\", \"bin_one\", \"bin_all\", \"multi_maj\", \"disagree_bin\"]\n",
    "\n",
    "# Write to CSV file\n",
    "with open('test.csv', 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "\n",
    "    # Write the header\n",
    "    csvwriter.writerow(header)\n",
    "\n",
    "    # Write the data\n",
    "    csvwriter.writerows(rows)"
   ],
   "id": "aa2effe7661319d",
   "outputs": [],
   "execution_count": 49
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
